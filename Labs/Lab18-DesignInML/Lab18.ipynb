{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 18\n",
    "\n",
    "Today, we will spend a bit of time on Decision Trees and Emsemble methods, before transitioning to examining the efficacy of an algorithm. Today, we will: \n",
    "\n",
    "0. Define standard metrics for efficacy\n",
    "1. Work on timing implementations of algorithms\n",
    "\n",
    "It will be tempting to read quickly through the preamble of this lab, but take your time here. These terms are critical to discussing machine learning algorithms. It is recommended that you either work individually or in a small group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning at Scale\n",
    "\n",
    "So far in the course, we have not paid particular attention to the efficacy of our algorithms. Efficiency becomes increasingly important as we scale our algorithms to work on larger and larger datasets. Instead, we have just coded for heuristic understanding of the underlying principles of machine learning. Today, we turn our attention to the standard measures for the efficacy of an implementation. \n",
    "\n",
    "Parts of this lab may feel similar to when we worked with Gradient Descent, we did consider the raw number of computations that would need to happen for each round of gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch\n",
    "\n",
    "Often we see comparisons of an implementation's training error compared to the number of _epochs._ An epoch is the point where the algorithm has seen the whole set of training data exactly one time.  \n",
    "\n",
    "We have seen examples where an algorithm has to work iteratively over the whole training dataset. With your group, list at least 3 such examples: \n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size\n",
    "\n",
    "There are other comparisons for an implementation's training error. Another common one is the _batch size_ or the number of training examples that the algorithm \"sees\" in each pass. \n",
    "\n",
    "What are two examples of where we see batch size as part of the design?\n",
    "\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterations\n",
    "\n",
    "When an algorithm relies on batches of the training data, we often consider the number of _iterations_ of the algorithm needed to complete one epoch (or to \"see\" all the training data). This number can be directly computed from the total number of data points and the batch size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs, Batch Sizes, and Iterations, oh my!\n",
    "\n",
    "Let's take a moment to look closer at a few of these algorithms via these metrics. For each row, fill in the relationship between epochs and iterations. We'll assume that there are $n$ data points. If there is a batch size that is neither 1 nor $n$, we denote that $b$. I've filled in row for you: \n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>Epochs</th>\n",
    "<th>Batch Size</th>\n",
    "<th>Iterations</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><strong>k-means</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>kNN</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Gradient Descent</strong></td>\n",
    "<td>1</td>\n",
    "<td>n</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Mini-Batch Gradient Descent</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Stochastic Gradient Descent</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Decision Trees</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time? \n",
    "\n",
    "While we can talk about the number of passes of the data through an algorithm, it would be more helpful, if we could _time_ our algorithms. Today, we will do just that! \n",
    "\n",
    "In this example, we will use the random forest from last time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "dogs_data = np.genfromtxt(\"lab16data.csv\", delimiter=',', skip_header=1)\n",
    "dogs_pd = pd.read_csv(\"lab16data.csv\", sep = \",\", index_col = \"Breed Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into the input variables and the target classes\n",
    "in_dog_data = dog_full_np[:,:-1]\n",
    "out_class = dog_full_np[:,-1]\n",
    "\n",
    "# Get the variable names \n",
    "var_names = list(dog_full_pd.columns)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing our implementations with `time`\n",
    "\n",
    "Using the `time` module, we can time how long it takes us to get from the starting to the end of training a random forest on our weather data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer: \n",
    "start_time = time.time()\n",
    "\n",
    "# Specify and fit the model\n",
    "grove = RandomForestClassifier(n_estimators=10, max_features = 3, max_depth=2, random_state=0)\n",
    "grove.fit(in_dog_data, out_class)\n",
    "\n",
    "# Stop the clock and determine the length of time\n",
    "stop_time = time.time()\n",
    "\n",
    "print(\"This took %s seconds to run\" % (stop_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making comparisons\n",
    "\n",
    "In this next section, we will compare your own implementations of k-means and kNN to the off-the-shelf ones. You will need:\n",
    "1. Your k-means implementation from HW2\n",
    "2. Your kNN implementation from Lab 7\n",
    "3. The associated data for both labs (you may want to copy this data into this directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data for your labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add your k-means implementation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your kNN implementation from Lab 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `time` to time k-means\n",
    "Using the `time` module, we can time how long it takes us to get from the starting to the end of your k-means implementation. Then time how long `sklearn` takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for your k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for sklearn's k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing implementations\n",
    "\n",
    "Which was faster? By how much? \n",
    "\n",
    "What do you think would happen if you had 100 million data points? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `time` to time k-means\n",
    "Using the `time` module, we can time how long it takes us to get from the starting to the end of your kNN implementation. Then time how long `sklearn` takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for your kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for sklearn's kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing implementations\n",
    "\n",
    "Which was faster? By how much? \n",
    "\n",
    "What do you think would happen if you had 100 million data points? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, create a slack post on **#lab18_submission** channel with 1) what surprised you most in this lab about the notion of *time* in this lab, and 2) answer the question: **Why are both epoch and run time important analysis for machine learning?** \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the preamble **Lab18.** If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. \n",
    "\n",
    "### Next Time\n",
    "\n",
    "We will look at benchmarking and bottlenecks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. [Epoch vs Batch Size vs Iterations](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)\n",
    "1. [Epoch, Iterations & Batch Size](https://medium.com/@ewuramaminka/epoch-iterations-batch-size-11fbbd4f0771)\n",
    "2. [How do you calculate program run time in python?](https://stackoverflow.com/questions/5622976/how-do-you-calculate-program-run-time-in-python)\n",
    "3. [How do I get time of a Python program's execution?](https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
