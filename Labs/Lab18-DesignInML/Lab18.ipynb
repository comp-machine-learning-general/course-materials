{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 18\n",
    "\n",
    "Today, we will spend a bit of time on Decision Trees and Emsemble methods, before transitioning to examining the efficacy of an algorithm. Today, we will: \n",
    "\n",
    "0. Define standard metrics for efficacy\n",
    "1. Work on timing implementations of algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning at Scale\n",
    "\n",
    "So far in the course, we have not paid particular attention to the efficacy of our algorithms. Instead, we have just coded for heuristic understanding of the underlying principles of machine learning. When we worked with Gradient Descent, we did consider the raw number of computations that would need to happen for each round of gradient descent. Today, we turn our attention to the standard measures for the efficacy of an implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch\n",
    "\n",
    "Often we see comparisons of an implementation's training error compared to the number of _epochs._ An epoch is the point where the algorithm has seen the whole set of training data. \n",
    "\n",
    "We have seen examples where an algorithm has to work repeatedly over the whole training dataset. Let's list at least 3 such examples: \n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size\n",
    "\n",
    "There are other comparisons for an implementation's training error. Another common one is the _batch size_ or the number of training examples that the algorithm \"sees\" in each pass. \n",
    "\n",
    "What are two examples of where we see batch size as part of the design?\n",
    "\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterations\n",
    "\n",
    "When an algorithm relies on batches of the training data, we often consider the number of _iterations_ of the algorithm needed to complete one epoch (or to \"see\" all the training data). This number can be directly computed from the total number of data points and the batch size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs, Batch Sizes, and Iterations, oh my!\n",
    "\n",
    "Taking a closer look at a few of algorithms via these metrics:\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>Epochs</th>\n",
    "<th>Batch Size</th>\n",
    "<th>Iterations</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><strong>k-means</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>kNN</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Gradient Descent</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Mini-Batch Gradient Descent</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Stochastic Gradient Descent</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Decision Trees</strong></td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time? \n",
    "\n",
    "While we can talk about the number of passes of the data through an algorithm, it would be more helpful, if we could _time_ our algorithms. Today, we will do just that! \n",
    "\n",
    "In this example, we will use the random forest from last time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "weather_data = np.genfromtxt(\"../Lab16-DecisionTrees/lab16data.csv\", delimiter=',', skip_header=1)\n",
    "weather_pd = pd.read_csv(\"../Lab16-DecisionTrees/lab16data.csv\", sep = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into the input variables and the target classes\n",
    "in_weather = weather_data[:,:4]\n",
    "out_class = weather_data[:,4]\n",
    "\n",
    "# Get the variable names \n",
    "var_names = list(weather_pd.columns)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing our implementations with `time`\n",
    "\n",
    "Using the `time` module, we can time how long it takes us to get from the starting the the end of training a random forest on our weather data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer: \n",
    "start_time = time.time()\n",
    "\n",
    "# Specify and fit the model\n",
    "grove = RandomForestClassifier(n_estimators=10, max_features = 3, max_depth=2, random_state=0)\n",
    "grove.fit(in_weather, out_class)\n",
    "\n",
    "# Stop the clock and determine the length of time\n",
    "stop_time = time.time()\n",
    "\n",
    "print(\"This took %s seconds to run\" % (stop_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making comparisons\n",
    "\n",
    "In this next section, we will compare your own implementations of k-means and kNN to the off-the-shelf ones. You will need:\n",
    "1. Your k-means implementation from HW2\n",
    "2. Your kNN implementation from Lab 7\n",
    "3. The associated data for both labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for your k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for sklearn's k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing implementations\n",
    "\n",
    "Which was faster? By how much? \n",
    "\n",
    "What do you think would happen if you had 100 million data points? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for your kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a time analysis for sklearn's kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing implementations\n",
    "\n",
    "Which was faster? By how much? \n",
    "\n",
    "What do you think would happen if you had 100 million data points? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, answer the question: **Why are both epoch and run time important analysis for machine learning?** Share your thoughts in a post on **#lab_submission** channel on slack with your answer. Your post must start with **Lab18** to get credit.  \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab18**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. \n",
    "\n",
    "### Next Time\n",
    "\n",
    "We will look at benchmarking and bottlenecks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. [Epoch vs Batch Size vs Iterations](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)\n",
    "1. [Epoch, Iterations & Batch Size](https://medium.com/@ewuramaminka/epoch-iterations-batch-size-11fbbd4f0771)\n",
    "2. [How do you calculate program run time in python?](https://stackoverflow.com/questions/5622976/how-do-you-calculate-program-run-time-in-python)\n",
    "3. [How do I get time of a Python program's execution?](https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
