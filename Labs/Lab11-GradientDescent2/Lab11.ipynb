{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11\n",
    "\n",
    "This week, we are focusing on gradient descent. Like last week, we wil be using the fake employee dataset with the goal of finding the best parameters for linear regression. The goals for this week are:\n",
    "\n",
    "0. ~Reviewing grid search and the drawbacks of it~\n",
    "1. ~Motivate the process for gradient descent~ \n",
    "2. Detail the steps of gradient descent\n",
    "3. Define the learning rate for gradient descent and the impact of it on the speed of the algorithm\n",
    "\n",
    "## ADD MINI BATCH!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Today\n",
    "\n",
    "Let us import the packages that we need for today and the dataset from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for later use\n",
    "\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=\"lightblue\")\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "    \n",
    "def place_parameter(p_vec, col, ax=None):\n",
    "    plt.scatter(p_vec[0],p_vec[1], c=col, marker = \"*\", s = 100)\n",
    "    \n",
    "def draw_parameter_path(p0,p1, col, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=col)\n",
    "    ax.annotate('', p1, p0, arrowprops=arrowprops)   \n",
    "    \n",
    "def compute_mse(truth_vec, predict_vec):\n",
    "    return np.mean((truth_vec - predict_vec)**2)\n",
    "    \n",
    "def compute_m_partial(in_vals, truth_vec, predict_vec):\n",
    "    return -2*np.mean(in_vals*(truth_vec-predict_vec))\n",
    "\n",
    "def compute_b_partial(truth_vec, predict_vec):\n",
    "    return -2*np.mean(truth_vec-predict_vec)\n",
    "\n",
    "def adjust_L(current_L, grad_step_num):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "employ_data = pd.read_csv(\"../Lab09/lab9data.csv\", sep = \",\")\n",
    "\n",
    "## numpy vectors of our inputs\n",
    "neuro = employ_data[[\"neuroticism\"]].to_numpy()\n",
    "perform = employ_data[[\"performance\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are we? \n",
    "\n",
    "Last class, we spent considerable time motivating the role of the gradient descent in stepping towards the minimum. As many of you noticed, our first five steps seemed to be not making much progress towards that goal. \n",
    "\n",
    "Today's class will be a periods of coding punctuated by discussion and brainstorming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Session 1 \n",
    "\n",
    "At its core, **gradient descent** is a series of steps dictated by the _gradient_ _descending_ an evaluation surface. \n",
    "\n",
    "In the below code block, create an iterative process that creates lists of $m$ values, $b$ values, and the MSE associated to it. We should be able to state the number of steps `n_steps` and decend that number of times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding session 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the submission for Lab 10, plot your path with the parameters selected by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your results here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding session 1 - Reflection 1\n",
    "\n",
    "Try a few values for `n_steps`, say up to 5000. Plot the resulting paths again in comparison to the parameters selected by the `sklearn` implementation of linear regression. \n",
    "\n",
    "What surprises you? What ideas/questions/concerns do you have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for additional exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for more exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for testing an idea (or two) for Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorming session 1\n",
    "\n",
    "What do we notice? Let's try to come up with at least 5 ideas/questions:\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding session 1 - Reflection 2\n",
    "\n",
    "Fix the value for `n_steps` to 200. This time vary the value for L from 0.0001 to 1. Plot the resulting paths again in comparison to the parameters selected by the `sklearn` implementation of linear regression. \n",
    "\n",
    "What surprises you? What ideas/questions/concerns do you have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for additional exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for more exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for testing an idea (or two) for Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorming session 2\n",
    "\n",
    "What do we notice? Let's try to come up with at least 5 ideas/questions:\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations in Gradient Descent\n",
    "\n",
    "We have two big considerations in gradient descent: 1) the size of the step that we are taking, and 2) the number of steps that we are taking.\n",
    "\n",
    "The first is governed in part by the **learning rate** which we have denoted as $L$. The learning rate effectively controls how much of an effect the gradient has on the parameter update. The second -- like the number of iterations within $k$-means -- is a bit more subtle, requiring an examination of **stopping conditions.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate + Step Size\n",
    "\n",
    "There are many ways to approach the learning rate and step size: \n",
    "\n",
    "0. Enforce a consistent step size by shrinking the gradient vector to be of length one and keeping a consistent learning rate.\n",
    "1. We could take an adaptative approach that is related to how many steps the algorithm has taken. That is, gradient descent could take bigger steps at the beginning of the path and then take increasingly smaller ones as it moves on. \n",
    "\n",
    "While easy to state the intuition of this second option, there are many ways that one could do this:\n",
    "* Decrease the value of $L$ with each step of the gradient descent either linearly or exponetially\n",
    "* Decrease the value of $L$ in a stepwise fashion every few steps \n",
    "\n",
    "Check out [this page](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1) for a few ideas. \n",
    "\n",
    "Choose one of these approaches to the learning rate and sketch out how you would like to code this. Then let's form two groups to implement an approach as the helper function `adjust_L` in the function block. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting $L$ in Gradient Descent\n",
    "\n",
    "Copy your current version of your gradient descent below and add your adjusting learning rate. \n",
    "\n",
    "Apply this implementation to our employee information. Then chart the path your gradient descent took and again compare it to the parameter values found by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent with varying L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent \n",
    "#                      with varying learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of steps (or GD Stopping conditions)\n",
    "\n",
    "Gradient descent at its core is a series of steps, but we have to say when we've taken enough steps. There are two considerations when determining that number. From a computational point of view, we also want to limit the maximum number of steps. However, we want to take enough steps that we reach the minimum, but not so many that we by-pass that minimum. \n",
    "\n",
    "In terms of testing to see if we have reached the minimum, let us recall a bit of calculus. Consider a one-dimensional curve, ie. one that you can draw on paper with your pencil. Draw $x$ and $y$ axes for reference. \n",
    "\n",
    "Now find a minima, and lay your pencil down such that the side of the pencil (ie. neither \"end\" of the pencil) touches the curve in one place. Notice that your pencil is parallel to the $x$ axis, or as we say, it's _flat._ Your pencil is a physical representative of the derivative. If we were to do something similar for an evaluation surface, we would use a board in place of the pencil. In this higher dimensional version, the board will be parallel to the parameter plane. \n",
    "\n",
    "When the derivative flattens, the rate of changes are close to 0. So encoding this arrival at a \"minima\" is equivalent to checking the size of the gradient, or checking to see when the length of the gradient is close to zero. \n",
    "\n",
    "We balance these consideration with two stopping conditions:\n",
    "1. We can set a hard limit on how many steps we want to take\n",
    "2. When the (length of the) gradient becomes small enough\n",
    "These stopping conditions feel very similar to those we encountered for $k$-means, in that the first limits the number of iterations and the second does a quick examination of the most recent progress that the algorithm has made. \n",
    "\n",
    "We will add these stopping conditions in two phases, checking the paths against the parameter values found by the `sklearn` implementation of linear regression. \n",
    "\n",
    "**_Note:_** To compute the length of a vector, you can either use:\n",
    "* `norm` within the linear algebra submodule (`linalg`) of `numpy`\n",
    "* The fact that $|\\nabla f| = \\sqrt{\\nabla f \\cdot \\nabla f}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a hard limit (ie. the max number of steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent with a maximum number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a stopping condition based on the length of the gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent with:\n",
    "#        1. a maximum number of steps AND\n",
    "#        2. length of the gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Let us put all these pieces Implement gradient descent with two stopping conditions and an option to vary the learning rate (or not!). \n",
    "\n",
    "Apply your implementation to our employee information. Then chart the path your gradient descent algorithm took and again compare it to the parameter values found by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation of Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different flavors of Gradient Descent\n",
    "\n",
    "Last time we talked about the number of MSE computations for grid search. Clearly gradient descent lowers the number of MSE computations, but within each MSE computation, there are also a number of computations dictated by the size of the dataset. \n",
    "\n",
    "Our dataset has 300? employees. For each computation of MSE for our example, how many arithmatic operations occur? Think about the _order_ of operations as you do this. Try to express your number in terms of $n_o$ the number of observations, $n_v$ the number of variables, and/or the $n_p$ the number of parameters.  \n",
    "\n",
    "When you have a number, consult with one person who is not currently sitting next to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent \n",
    "\n",
    "Stochastic Gradient Descent attempts to overcome the number of computations within the MSE by using just one randomly chosen datapoint for each step of the gradient descent. The gradient descent that we implemented earlier is also called _batch gradient descent_ because it consults a _batch_ of data, instead of just one datapoint, in the decision of where to step. \n",
    "\n",
    "Create an implementation of stochastic gradient descent, where for each step, you randomly select a datapoint to act in place of the dataset. Before you get started, a few hints and warnings:\n",
    "* You might want to start with copying your code from above\n",
    "* Be careful to not overwrite the dataset when you select your random point\n",
    "\n",
    "Apply your implementation to our employee information. Then chart the path your stochastic gradient descent took in one color and the path your batch gradient descent took in a second color. Compare both paths to the parameter values found by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation of Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the paths given by Stochastic and Batch Gradient Descents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "\n",
    "You may want to use EEEE and FFFF to see how long each implementation takes in terms of TIME THING. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for time checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "Mini-Batch Gradient Descent is the compromise between batch and stochastic gradient descent using small collections of the data in each step, instead of using all of the data or using just one data point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next week\n",
    "\n",
    "A deeper look at the training and testing phases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, Create a plot with both your stochastic and batch gradient descent paths compared to the best values of $m$ and $b$ according to the linear regression from `sklearn`. Share your plot in a post on **#lab_submission** channel on slack and note which path seems better to you. Your post must start with **Lab11** to get credit. \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab11**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. _Doing Data Science: Straight talk from the frontline_ by C. O'Neil & R. Schutt (2014)\n",
    "1. [BATCH GRADIENT DESCENT VS STOCHASTIC GRADIENT DESCENT](https://www.bogotobogo.com/python/scikit-learn/scikit-learn_batch-gradient-descent-versus-stochastic-gradient-descent.php)\n",
    "2. [Gradient descent algorithms and adaptive learning rate adjustment methods](https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be)\n",
    "3. [Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1)\n",
    "4. [Stochastic Gradient Descent on Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "5. [Gradient Descent Lecture notes by Ryan Tibshirani](https://www.stat.cmu.edu/~ryantibs/convexopt/lectures/grad-descent.pdf)\n",
    "6. [norm helpfile in numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.norm.html)\n",
    "6. [Notation for grad](https://tex.stackexchange.com/questions/219951/laplaces-equation-symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
