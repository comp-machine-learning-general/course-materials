{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11\n",
    "\n",
    "This week, we are focusing on gradient descent. Like last week, we wil be using the fake employee dataset with the goal of finding the best parameters for linear regression. The goals for this week are:\n",
    "\n",
    "0. ~Reviewing grid search and the drawbacks of it~\n",
    "1. ~Motivate the process for gradient descent~ \n",
    "2. Detail the steps of gradient descent\n",
    "3. Define the learning rate for gradient descent and the impact of it on the speed of the algorithm\n",
    "4. Implement different versions of gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Today\n",
    "\n",
    "Let us import the packages that we need for today and the dataset from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for later use\n",
    "\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=\"lightblue\")\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "    \n",
    "def place_parameter(p_vec, col, ax=None):\n",
    "    plt.scatter(p_vec[0],p_vec[1], c=col, marker = \"*\", s = 100)\n",
    "    \n",
    "def draw_parameter_path(p0,p1, col, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=col)\n",
    "    ax.annotate('', p1, p0, arrowprops=arrowprops)   \n",
    "    \n",
    "def compute_mse(truth_vec, predict_vec):\n",
    "    return np.mean((truth_vec - predict_vec)**2)\n",
    "    \n",
    "def compute_m_partial(in_vals, truth_vec, predict_vec):\n",
    "    return -2*np.mean(in_vals*(truth_vec-predict_vec))\n",
    "\n",
    "def compute_b_partial(truth_vec, predict_vec):\n",
    "    return -2*np.mean(truth_vec-predict_vec)\n",
    "\n",
    "def adjust_L(current_L, grad_step_num):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "employ_data = pd.read_csv(\"../Lab09/lab9data.csv\", sep = \",\")\n",
    "\n",
    "## numpy vectors of our inputs\n",
    "neuro = employ_data[[\"neuroticism\"]].to_numpy()\n",
    "perform = employ_data[[\"performance\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where are we? \n",
    "\n",
    "Last class, we spent considerable time motivating the role of the gradient descent in stepping towards the minimum. As many of you noticed, our first 50 steps made some progress towards that goal. \n",
    "\n",
    "Today's class will be a periods of coding punctuated by discussion and brainstorming. \n",
    "\n",
    "To begin, copy your code that creates the list of $m$ values, $b$ values, and the MSE associated to each pairing. I've copied the starter code from last lab to help you hone in on which block I mean: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the number of steps you wish to take\n",
    "# Set your learning rate\n",
    "n_steps = ???\n",
    "L = 0.01\n",
    "\n",
    "# Initialize starting parameters\n",
    "m = ??\n",
    "b = ??\n",
    "\n",
    "# Create empty lists to store values for m, b, and the associated MSE\n",
    "outm = []\n",
    "outb = ???\n",
    "outmse = ???\n",
    "\n",
    "# Create an iterative process (ie. a loop) that will take N_STEPS\n",
    "for stp in range(??):\n",
    "    # For the current values of m and b: \n",
    "    \n",
    "    # 1. Compute the MSE\n",
    "    preds = ???\n",
    "    errormse = compute_mse(??,??)\n",
    "    \n",
    "    # 2. Store m, b, and the associated MSE in the output lists:\n",
    "    outm.append(m)\n",
    "    outb.append(??)\n",
    "    outmse.??\n",
    "    \n",
    "    # Update m and b by:\n",
    "    \n",
    "    # 1. Computing the gradient\n",
    "    d_m = compute_m_partial(???,???,???)\n",
    "    d_b = ???\n",
    "    \n",
    "    # Update the values for m and b\n",
    "    m = m - (?*d_m)\n",
    "    b = ??\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring $L$ \n",
    "\n",
    "Fix the value for `n_steps` to 200. This time, run gradient descent 3 times, each with a different value for L. Limit your options to between 0.00001 to 0.1. Plot the resulting paths again in comparison to the parameters selected by the `sklearn` implementation of linear regression. \n",
    "\n",
    "What surprises you? What ideas/questions/concerns do you have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for additional exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for more exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for testing an idea (or two) for Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorming session\n",
    "\n",
    "What do you notice? With your group, try to come up with at least 5 ideas/questions:\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations in Gradient Descent\n",
    "\n",
    "We have two big considerations in gradient descent: 1) the size of the step that we are taking, and 2) the number of steps that we are taking.\n",
    "\n",
    "The first is governed in part by the **learning rate** which we have denoted as $L$. The learning rate effectively controls how much of an effect the gradient has on the parameter update. The second -- like the number of iterations within $k$-means -- is a bit more subtle, requiring an examination of **stopping conditions.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate + Step Size\n",
    "\n",
    "There are many ways to approach the learning rate and step size: \n",
    "\n",
    "0. Enforce a consistent step size by shrinking the gradient vector to be of length one and keeping a consistent learning rate.\n",
    "1. We could take an adaptative approach that is related to how many steps the algorithm has taken. That is, gradient descent could take bigger steps at the beginning of the path and then take increasingly smaller ones as it moves on. \n",
    "\n",
    "While easy to state the intuition of this second option, there are many ways that one could do this:\n",
    "* Decrease the value of $L$ with each step of the gradient descent either linearly or exponetially\n",
    "* Decrease the value of $L$ in a stepwise fashion every few steps \n",
    "\n",
    "Choose one of these approaches to the learning rate and sketch out how you would like to code this. Then with your group, implement one approach for varying L as the helper function `adjust_L` in the function block. \n",
    "\n",
    "*Aside:* [This page](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1) develop and expand the above ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting $L$ in Gradient Descent\n",
    "\n",
    "Now let's incorporate your helper function into your version of gradient descent. I've copied an edited version of the above starter code below.\n",
    "\n",
    "Apply this implementation to our employee information. Then chart the path your gradient descent took and again compare it to the parameter values found by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent with varying L\n",
    "\n",
    "# Initialize the number of steps you wish to take\n",
    "n_steps = ???\n",
    "\n",
    "# Initialize starting parameters\n",
    "m = ??\n",
    "b = ??\n",
    "\n",
    "# Initialize L \n",
    "L = ???\n",
    "\n",
    "# Create empty lists to store values for m, b, and the associated MSE\n",
    "outm = []\n",
    "outb = ???\n",
    "outmse = ???\n",
    "\n",
    "# Create an iterative process (ie. a loop) that will take N_STEPS\n",
    "for stp in range(??):\n",
    "    # For the current values of m and b: \n",
    "    \n",
    "    # 1. Compute the MSE\n",
    "    preds = ???\n",
    "    errormse = compute_mse(??,??)\n",
    "    \n",
    "    # 2. Store m, b, and the associated MSE in the output lists:\n",
    "    outm.append(m)\n",
    "    outb.append(??)\n",
    "    outmse.??\n",
    "    \n",
    "    # Update m and b by:\n",
    "    \n",
    "    # 1. Computing the gradient\n",
    "    d_m = compute_m_partial(???,???,???)\n",
    "    d_b = ???\n",
    "    \n",
    "    # Update the values for m and b\n",
    "    m = m - (?*d_m)\n",
    "    b = ??\n",
    "    \n",
    "    # Update learning rate\n",
    "    L = ???\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m and b as given by sklearn: \n",
    "\n",
    "# 1. Define the model: \n",
    "sk_line = linear_model.LinearRegression()\n",
    "\n",
    "# 2. Fit the model to our data: \n",
    "sk_mod = sk_line.fit(neuro, perform)\n",
    "\n",
    "# 3. Extract coefficients:\n",
    "m_sk = sk_mod.coef_\n",
    "b_sk = sk_mod.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent \n",
    "#                      with varying learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of steps (or GD Stopping conditions)\n",
    "\n",
    "Gradient descent at its core is a series of steps, but we have to say when we've taken enough steps. There are two considerations when determining that number. From a computational point of view, we also want to limit the maximum number of steps. However, we want to take enough steps that we reach the minimum, but not so many that we by-pass that minimum. \n",
    "\n",
    "In terms of testing to see if we have reached the minimum, let us recall a bit of calculus. Consider a one-dimensional curve, ie. one that you can draw on paper with your pencil. Draw $x$ and $y$ axes for reference. \n",
    "\n",
    "Now find a minima, and lay your pencil down such that the side of the pencil (ie. neither \"end\" of the pencil) touches the curve in one place. Notice that your pencil is parallel to the $x$ axis, or as we say, it's _flat._ Your pencil is a physical representative of the derivative. If we were to do something similar for an evaluation surface, we would use a board in place of the pencil. In this higher dimensional version, the board will be parallel to the parameter plane. \n",
    "\n",
    "When the derivative flattens, the rate of changes are close to 0. So encoding this arrival at a \"minima\" is equivalent to checking the size of the gradient, or checking to see when the length of the gradient is close to zero. \n",
    "\n",
    "We balance these consideration with two stopping conditions:\n",
    "1. We can set a hard limit on how many steps we want to take\n",
    "2. When the (length of the) gradient becomes small enough\n",
    "\n",
    "These stopping conditions feel very similar to those we encountered for $k$-means, in that the first limits the number of iterations and the second does a quick examination of the most recent progress that the algorithm has made. \n",
    "\n",
    "We will add these stopping conditions in two phases, checking the paths against the parameter values found by the `sklearn` implementation of linear regression. \n",
    "\n",
    "**_Note:_** To compute the length of a vector, you can either use:\n",
    "* `norm` within the linear algebra submodule (`linalg`) of `numpy`\n",
    "* The fact that $|\\nabla f| = \\sqrt{\\nabla f \\cdot \\nabla f}$, where $\\nabla f$ denotes the gradient of the function $f$. In this case $\\nabla f = [\\textrm{partial with respect to m},\\textrm{partial with respect to b}]$.\n",
    "\n",
    "We add these stopping conditions in waves. Again, I'll be copying previous code shells to give you a starting point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a hard limit (ie. the max number of steps)\n",
    "\n",
    "# Gradient Descent with varying L and a max-number of steps\n",
    "\n",
    "# Initialize the max number of steps you wish to take\n",
    "max_steps = ???\n",
    "\n",
    "# Initialize starting parameters\n",
    "m = ??\n",
    "b = ??\n",
    "\n",
    "# Initialize L \n",
    "L = ???\n",
    "\n",
    "# Create empty lists to store values for m, b, and the associated MSE\n",
    "outm = []\n",
    "outb = ???\n",
    "outmse = ???\n",
    "\n",
    "# Create an iterative process (ie. a loop) that will take N_STEPS\n",
    "for stp in range(??):\n",
    "    # For the current values of m and b: \n",
    "    \n",
    "    # 1. Compute the MSE\n",
    "    preds = ???\n",
    "    errormse = compute_mse(??,??)\n",
    "    \n",
    "    # 2. Store m, b, and the associated MSE in the output lists:\n",
    "    outm.append(m)\n",
    "    outb.append(??)\n",
    "    outmse.??\n",
    "    \n",
    "    # Update m and b by:\n",
    "    \n",
    "    # 1. Computing the gradient\n",
    "    d_m = compute_m_partial(???,???,???)\n",
    "    d_b = ???\n",
    "    \n",
    "    # Update the values for m and b\n",
    "    m = m - (?*d_m)\n",
    "    b = ??\n",
    "    \n",
    "    # Update learning rate\n",
    "    L = ???\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did anything substantively change in your implementation above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent with a maximum number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a stopping condition based on the length of the gradient \n",
    "# Adding a hard limit (ie. the max number of steps)\n",
    "\n",
    "# Gradient Descent with varying L and a max-number of steps\n",
    "\n",
    "# Initialize the max number of steps you wish to take\n",
    "max_steps = ???\n",
    "\n",
    "# Initialize starting parameters\n",
    "m = ??\n",
    "b = ??\n",
    "\n",
    "# Initialize L \n",
    "L = ???\n",
    "\n",
    "# Set a tolerance for the smallest you will allow \n",
    "# the length of the gradient to be before stopping \n",
    "grad_tol = 0.01\n",
    "\n",
    "# Create empty lists to store values for m, b, and the associated MSE\n",
    "outm = []\n",
    "outb = ???\n",
    "outmse = ???\n",
    "\n",
    "# Create an iterative process (ie. a loop) that will take N_STEPS\n",
    "for stp in range(??):\n",
    "    # For the current values of m and b: \n",
    "    \n",
    "    # 1. Compute the MSE\n",
    "    preds = ???\n",
    "    errormse = compute_mse(??,??)\n",
    "    \n",
    "    # 2. Store m, b, and the associated MSE in the output lists:\n",
    "    outm.append(m)\n",
    "    outb.append(??)\n",
    "    outmse.??\n",
    "    \n",
    "    # Update m and b by:\n",
    "    \n",
    "    # 1. Computing the gradient\n",
    "    d_m = compute_m_partial(???,???,???)\n",
    "    d_b = ???\n",
    "    \n",
    "    # Compute the length of the gradient\n",
    "    norm_grad = ??\n",
    "    \n",
    "    # If the length of the gradient is small enough, stop iterating\n",
    "    if norm_grad < ???:\n",
    "        break\n",
    "        \n",
    "    # Update the values for m and b\n",
    "    m = m - (?*d_m)\n",
    "    b = ??\n",
    "    \n",
    "    # Update learning rate\n",
    "    L = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent with:\n",
    "#        1. a maximum number of steps AND\n",
    "#        2. length of the gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Let us put all these pieces and implement gradient descent for linear regression with two stopping conditions and an option to vary the learning rate (or not!). Your implementation should be a function that takes in the following arguments: \n",
    "1. Your input variable for regression\n",
    "2. Your output variable for regression\n",
    "3. The max number of steps\n",
    "4. A flag allowing for one to vary (or not) the learning rate\n",
    "\n",
    "Your implementation should **return** just the the values for $m$ and $b$ that gradient descent last computes before being stopped by a stopping condition\n",
    "\n",
    "Apply your implementation to our employee information. Then chart the path your gradient descent algorithm took and again compare it to the parameter values found by the `sklearn` implementation of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation of Gradient Descent as a function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the path given by Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different flavors of Gradient Descent\n",
    "\n",
    "Last time we talked about the number of MSE computations for grid search. Clearly gradient descent lowers the number of MSE computations, but within each MSE computation, there are also a number of computations dictated by the size of the dataset. \n",
    "\n",
    "Our dataset has 1000 employees. For each computation of MSE for our example, how many arithmatic operations occur? Think about the _order_ of operations as you do this. Try to express your number in terms of $n_o$ the number of observations, $n_v$ the number of variables, and/or the $n_p$ the number of parameters.  \n",
    "\n",
    "When you have a number, consult with at least one member of your group. (You may decide to use the chat function in gather or slack to do this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent \n",
    "\n",
    "Stochastic Gradient Descent (SGD) attempts to overcome the number of computations within the MSE by using just one randomly chosen datapoint for each step of the gradient descent. The gradient descent that we implemented earlier is also called _batch gradient descent_ because it consults a _batch_ of data, instead of just one datapoint, in the decision of where to step. \n",
    "\n",
    "Create an implementation of stochastic gradient descent, where for each step, you randomly select one datapoint to act in place of the dataset. Before you get started, a few hints and warnings:\n",
    "* You might want to start with copying your code from above\n",
    "* Be careful to **not overwrite** the dataset when you select your random point\n",
    "* You may want to see how lab 8 uses `np.random.choice()` to select 4 points in our second regression line. \n",
    "\n",
    "\n",
    "Apply your implementation to our employee information. Then chart the path your stochastic gradient descent took in one color and the path your batch gradient descent took in a second color. Compare both paths to the parameter values found by the `sklearn` implementation of linear regression. \n",
    "\n",
    "*Aside:* In the most precise version of SGD, we use each datapoint exactly once before repeating any of the data. Each pass over full dataset is called an *epoch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation of Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot of the paths given by Stochastic and Batch Gradient Descents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "Mini-Batch Gradient Descent is the compromise between batch and stochastic gradient descent using small collections of the data in each step, instead of using all of the data or using just one data point. Mini-batch takes *batches* of $n_b$ datapoints in each step of the gradient descent. \n",
    "\n",
    "Create an implementation of mini-batch gradient descent, where you set the size of the batches (that is the value of $n_b$), and where for each step, you randomly select $n_b$ datapoint to act in place of the dataset. Before you get started, a few hints and warnings:\n",
    "* You might want to start with copying your code from above\n",
    "* Be careful to **not overwrite** the dataset when you select your random point\n",
    "* You may want to see how lab 8 uses `np.random.choice()` to select 4 points in our second regression line. \n",
    "\n",
    "\n",
    "Apply your implementation to our employee information. Then chart the path your mini-batch gradient descent took in one color and the path your batch gradient descent took in a second color. Compare both paths to the parameter values found by the `sklearn` implementation of linear regression. \n",
    "\n",
    "\n",
    "*Aside:* In the most precise version of Mini-batch, we parcel the data into batches, and then use each batch exactly once before repeating any of the batches. Just as with SGD, each pass over full dataset is called an *epoch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next week\n",
    "\n",
    "A deeper look at the training and testing phases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, create a plot with both your stochastic and mini-batch gradient descent paths compared to the best values of $m$ and $b$ according to the linear regression from `sklearn`. Share your plot in a post on **#lab11_submission** channel on slack and note which path seems better to you.  \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab11**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. _Doing Data Science: Straight talk from the frontline_ by C. O'Neil & R. Schutt (2014)\n",
    "1. [BATCH GRADIENT DESCENT VS STOCHASTIC GRADIENT DESCENT](https://www.bogotobogo.com/python/scikit-learn/scikit-learn_batch-gradient-descent-versus-stochastic-gradient-descent.php)\n",
    "2. [Gradient descent algorithms and adaptive learning rate adjustment methods](https://towardsdatascience.com/gradient-descent-algorithms-and-adaptive-learning-rate-adjustment-methods-79c701b086be)\n",
    "3. [Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1)\n",
    "4. [Stochastic Gradient Descent on Wikipedia](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "5. [Gradient Descent Lecture notes by Ryan Tibshirani](https://www.stat.cmu.edu/~ryantibs/convexopt/lectures/grad-descent.pdf)\n",
    "6. [norm helpfile in numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.norm.html)\n",
    "6. [Notation for grad](https://tex.stackexchange.com/questions/219951/laplaces-equation-symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
