{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9\n",
    "\n",
    "Today is a second day of vocabularies. Today we will examine _parameters_ and _hyperparameters_ and acquaint ourselves with the idea of parameters stored as vectors. Today's goals are:\n",
    "\n",
    "0. Compare and contrast parameters and hyper-parameters\n",
    "1. Explore how parameters can be viewed and interacted with as vectors \n",
    "2. Discuss grid search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "\n",
    "The first part of this lab revisits all the algorithms and methods that we have explored so far. Let's start by making a list of each method so far, noting 1) the kind (supervised vs. unsupervised), 2) the inputs needed to use the method (other than data), and 3) any other numbers that are involved or set during that method. \n",
    "\n",
    "We'll use this listing in our following discussions. I'll do the first one: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <th>Type</th>\n",
    "    <th>Inputs</th>\n",
    "    <th>Numbers set/involved</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<th>k-means</th>\n",
    "    <td>unsupervised </td>\n",
    "    <td>$k$</td>\n",
    "    <td>labels, cluster centers</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <td>Type</td>\n",
    "    <td>Inputs</td>\n",
    "    <td>Numbers set/involved</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <td>Type</td>\n",
    "    <td>Inputs</td>\n",
    "    <td>Numbers set/involved</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>...</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>...</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kinds of inputs do we have? What trends do you notice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Hyper-) Parameters\n",
    "\n",
    "In most processes in machine learning, we are working to fit a model or a process to our data. This fitting involves both the data that we fit to and determining the values of various numbers. These numbers are either _parameters_ or _hyperparameters._ \n",
    "\n",
    "### Quick Definitions - \n",
    "\n",
    "**Hyper-parameters** are numbers that are set by the researcher. These can be set without knowing anything about the data that we are fitting to. \n",
    "**Parameters** are numbers whose values are dictated by the data. \n",
    "\n",
    "With these quick definitions, look back at your list from before and determine which numbers are hyper-parameters and which are parameters. Then fill in the below table: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <th>Hyper-parameters</th>\n",
    "    <th>Parameters</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<th>k-means</th>\n",
    "    <td> ... </td>\n",
    "    <td> ...</td>\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <td>Hyper-parameters</td>\n",
    "    <td>Parameters</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Method/Algorithm</th>\n",
    "    <td>Hyper-parameters</td>\n",
    "    <td>Parameters</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>...</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>...</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters\n",
    "\n",
    "Setting parameters is easier of the two types. Usually you use an algorithm or method (like linear regression) that has a process for setting the parameters ($m$ and $b$) given the data. Essentially, once you have made your choices regarding method and hyper-parameter values, then the data will finish the determination for the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Hyper-Parameters\n",
    "\n",
    "Selecting the value for hyper-parameters must come before you can apply your method. For example, you cannot run k-means without a value for $k$. Choosing these values is more of an art because -- unlike setting parameters -- your data can't tell you the best choice. You might be able to make an educated guess by visualizing the data. \n",
    "\n",
    "There is no one right way to choose your hyper-parameters, but you can apply external evaluation or validation techniques to assist you in this choice. So far, we have used elbowology in combination of some external notion of \"goodness.\" For each possible value for the hyper-parameter, we calculated our notion of \"goodness\" and we selected the one that creates the deepest \"elbow\" when we graph the possible values for the hyper-parameter against the resulting \"goodness\" value.\n",
    "\n",
    ">\"Wait, wait, wait. You said the data couldn't tell us what value the hyper-parameter should be.\" -- A natural human reaction \n",
    "\n",
    "This reaction is absolutely appropriate. While we use data to compute the notion of \"goodness\", there is no accepted way to determine where the elbow of your graph of \"goodness\" values is. That decision still requires finesse on the part of the researcher. So no, the data doesn't \"tell\" us what the value should be, but we do certainly use the data to make a reasonable decision about our hyper-parameters.\n",
    "\n",
    "#### An Imperfect metaphor\n",
    "One (imperfect) metaphor is deciding hyper-parameters is akin to choosing the type of clothing - dress, shirt, pants - and the parameters are then set by the tailor fitting the clothing to the person wearing it. The tailor does not fundamentally change the garment, but rather adjusts the lengths of various aspects of the garment to fit the person.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods with both Hyper-Parameters and Parameters\n",
    "\n",
    "Many methods have both hyper-parameters and parameters. This speaks to our intuition that we need to make some decisions before we deploy a method and then have some pieces tuned (or fit more closely) to our particular situation. \n",
    "\n",
    "**Question** - Which of the methods that we have seen have both hyper-parameters and parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing for coding pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib notebook \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d \n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "employ_data = pd.read_csv(\"lab9data.csv\", sep = \",\")\n",
    "\n",
    "## numpy vectors of our inputs\n",
    "neuro = employ_data[[\"neuroticism\"]].to_numpy()\n",
    "perform = employ_data[[\"performance\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for later use\n",
    "\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=\"lightblue\")\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "    \n",
    "def place_parameter(p_vec, col, ax=None):\n",
    "    plt.scatter(p_vec[0],p_vec[1], c=col, marker = \"*\")\n",
    "    \n",
    "def draw_parameter_path(p0,p1, col, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, color=col)\n",
    "    ax.annotate('', p1, p0, arrowprops=arrowprops)   \n",
    "    \n",
    "def compute_mse(truth_vec, predict_vec):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters as vectors\n",
    "\n",
    "We can think of parameters as a list of values with each value existing on its own numberline that is separate from every other parameters' numberlines. The issue with this view is that we see the parameters as disconnected from each other. Another view is to consider the parameters as vectors. \n",
    "\n",
    "Take our example from last time, we were fitting lines to our data. In this example we have two parameters $m$ (the slope of a line) and $b$ (the intercept or where the line crosses the $x = 0$ line). We can see these as a vector in this space in the shape of $[m,b]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Set axis limits\n",
    "xmin = -5\n",
    "xmax = 10\n",
    "ymin = -5\n",
    "ymax = 10\n",
    "\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([ymin, ymax])\n",
    "\n",
    "# Build axes\n",
    "draw_vector([xmin,0], [xmax,0])\n",
    "draw_vector([0,ymin], [0,ymax])\n",
    "\n",
    "# Create grid and labels\n",
    "plt.grid(True)\n",
    "plt.xlabel('Value for m --->')\n",
    "plt.ylabel('Value for b --->')\n",
    "plt.title('Parameter Vector space')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull the $m$ and $b$ values for our first two lines that we made last time and place them in this space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Set axis limits\n",
    "xmin = -5\n",
    "xmax = 10\n",
    "ymin = -5\n",
    "ymax = 10\n",
    "\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([ymin, ymax])\n",
    "\n",
    "# Build axes\n",
    "draw_vector([xmin,0], [xmax,0])\n",
    "draw_vector([0,ymin], [0,ymax])\n",
    "\n",
    "# Add your m's and b's here:\n",
    "place_parameter([m1,b1],\"red\")\n",
    "place_parameter([m2,b2],\"green\")\n",
    "\n",
    "# Create grid and labels\n",
    "plt.grid(True)\n",
    "plt.xlabel('Value for m --->')\n",
    "plt.ylabel('Value for b --->')\n",
    "plt.title('Parameter Vector space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this view, we have no information about how these parameters relate to the data. Today, we will perform a _grid search_ and build a surface that will connect our parameters to the data. \n",
    "\n",
    "### Grid Search\n",
    "\n",
    "In a grid search, we create a list for each parameter that we want to investigate and then we create a grid that encapsulates all combinations of values from these parameter lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "    <th></th>\n",
    "<th>m = 0</th>\n",
    "    <th>m = 0.5</th>\n",
    "    <th>m = 1.5</th>\n",
    "    <th>m = 2</th>\n",
    "    <th>...</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<th>b = 0</th>\n",
    "    <td>(0,0) </td>\n",
    "    <td>(0,0.5)</td>\n",
    "    <td>(0,1.5) </td>\n",
    "    <td>(0,2)</td>\n",
    "    <td>(0,...) </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>b = 1/3</th>\n",
    "    <td>(1/3,0) </td>\n",
    "    <td>(1/3,0.5)</td>\n",
    "    <td>(1/3,1.5) </td>\n",
    "    <td>(1/3,2)</td>\n",
    "    <td>(1/3,...) </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>b = 2/3</th>\n",
    "    <td>(2/3,0) </td>\n",
    "    <td>(2/3,0.5)</td>\n",
    "    <td>(2/3,1.5) </td>\n",
    "    <td>(2/3,2)</td>\n",
    "    <td>(2/3,...) </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>b = 1</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>b = 4/3</th>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "    <td>...</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a grid search, we then replace each entry with some evaluation metric relating to how those parameters do predicting our data. \n",
    "\n",
    "For example, we would use the listed $m$ and $b$ to build a line `perform_guess = m*neuro_score + b`. Then we would compare the guesses for the performance scores to the ground truth. Today we will use the _mean squared error_ for this comparison:\n",
    "\n",
    "$MSE(truth, guess) = avg(truth - guess)^2$\n",
    "\n",
    "In the function block above, there is a fourth function that has only `pass` in the body of the function. Fill in the details for taking in a vector of truth and a vector of predictions and returning the average of the squared difference between them. Use the `function testing` block to check your function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating evaluation matrix\n",
    "\n",
    "_Note:_ We are not making the full use of the power of `numpy` in this section. We are doing this the brute force way to better understand what each step is doing in the grid search. \n",
    "\n",
    "To create the evaluation matrix, we need to:\n",
    "1. Create the range of parameter values that we are interested in\n",
    "2. Try all possible combinations of the parameters in our model\n",
    "3. Store how \"well\" those parameters do\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the possible values for our parameters\n",
    "m_vec = np.arange(-3, 10, 0.1)\n",
    "b_vec = np.arange(-2, 60, 0.2)\n",
    "\n",
    "# Create a place to store the values \n",
    "# HINT - Look at the above matrix! \n",
    "eval_mat = \n",
    "\n",
    "# Try (or loop) over all possible combinations\n",
    "# HINT think nested\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is that our MSE is close to zero. In this evaluation matrix, we could simply find the minimum and use those parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peek at your results\n",
    "\n",
    "plt.imshow(eval_mat,cmap='viridis')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ummmm... What does this mean? \n",
    "\n",
    "Instead let's look at this matrix as a 3D object (also known as a surface) instead. To do that, we'll use some of the tricks from Lab 5 combined with `meshgrid`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "bs,ms = np.meshgrid(b_vec,m_vec)\n",
    "\n",
    "# Create the SCATTER() plot with colors\n",
    "ax.plot_surface(ms,bs, eval_mat, cmap='viridis',edgecolor='none');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is that our MSE is close to zero. In this evaluation matrix, we could simply find the minimum and use those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.unravel_index(np.argmin(eval_mat, axis=None), eval_mat.shape)\n",
    "\n",
    "# Trick from example on https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum of eval_mat is\", eval_mat[ind], \"\\n\")\n",
    "print(\"This min is found at m =\", ms[ind], \"and b=\", bs[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why are we plotting anything at all? Well, grid search is not the most efficient way to search for parameters. So what could be alternative? \n",
    "\n",
    "Notice, we have not actually computed a linear regression. Instead we have the form of the output ($y = m*x +b$) and have been just putting parameters into the $m$ and $b$ places. So how could we do this kind of \"blind\" search better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent....\n",
    "\n",
    "NEXT WEEK! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "1. [Linear Regression using Gradient Descent](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931)\n",
    "2. [How to Create an Empty Figure with Matplotlib in Python](http://www.learningaboutelectronics.com/Articles/How-to-create-an-empty-figure-with-matplotlib-in-Python.php)\n",
    "3. [Findobj Demo](https://matplotlib.org/3.1.1/gallery/misc/findobj_demo.html#sphx-glr-gallery-misc-findobj-demo-py)\n",
    "4. [3d plots in matplotlib](https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html)\n",
    "5. [meshgrid in matplotlib](https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html)\n",
    "6. [argmin in numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html)\n",
    "7. [Three-Dimensional Plotting in Matplotlib](https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
