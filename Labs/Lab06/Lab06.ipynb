{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "Today we continue exploring **dimension reduction** to help us get a handle on large dimensional data. Today's goals are:\n",
    "\n",
    "0. Understand how to use the `sklearn` implementation for PCA\n",
    "1. Determine what the \"right\" lower dimension is\n",
    "2. Introduce _Singular Value Decomposition_\n",
    "3. Compare and contrast PCA and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier comparisons, we will continue with the ever exciting `students_info.csv` file. Please import this in `pandas` and then create a `numpy` array with only the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "students = pd.read_csv(\"../Lab03/students_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create justnum with only the numerical data\n",
    "justnum = students[[\"coffee\", \"sleep\", \"gym\", \"gpa\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "Recall that for PCA, we need to have normalized data. Before continuing, create `justnum_std` that _standardizes_ each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing our variables:\n",
    "mean_vec = np.mean(justnum, axis=0)\n",
    "sd_vec = np.std(justnum, axis=0)\n",
    "\n",
    "justnum_std = justnum.copy()\n",
    "\n",
    "for i in range(justnum.shape[1]):\n",
    "    justnum_std[:,i] = (justnum[:,i] - mean_vec[i]*np.ones(justnum.shape[0]))/sd_vec[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your creation of justnum_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to create a few plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another block for exploration \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA in `sklearn`\n",
    "\n",
    "PCA in `sklearn` works much the way that kmeans did. We first set up how PCA will function and then apply the particular PCA that we have crafted to our data. \n",
    "\n",
    "As we did with kmeans, we will take each step individually, exploring the output that we generate. \n",
    "\n",
    "In the below code block, we have one possible setting of `PCA()` in `sklearn`.\n",
    "* What _type_ is the output and what information is contained within `PCA`? \n",
    "* What are the various parameters doing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one: Set up PCA\n",
    "pca_alg = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False)\n"
     ]
    }
   ],
   "source": [
    "# Code block for further discovery\n",
    "type(pca_alg)\n",
    "print(pca_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with kmeans, now that we have set up our PCA, we can _fit_ it to our data. We can `fit` our data and then `transform` it; or if we prefer, we can do both using `fit_transform`.\n",
    "\n",
    "#### Using `.fit()`\n",
    "\n",
    "This first fitting applies our PCA to the data. What _type_ is the output and what information is contained within `pfit`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfit = pca_alg.fit(justnum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e46dbd6b8991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Code block for further discovery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpca_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "# Code block for further discovery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not immediately obvious how to access the principal components. The result of `.fit()` wraps this information inside a class style object. We can use `.components_` to access the principal components: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the resulting components\n",
      " (2, 4)\n",
      "\n",
      " Actual components \n",
      " [[-0.68413286  0.11610783 -0.69792798 -0.17713762]\n",
      " [ 0.19357127  0.70157473  0.09919856 -0.67858876]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the resulting components\\n\", pfit.components_.shape)\n",
    "\n",
    "print(\"\\n Actual components \\n\",pfit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this what we expect to see? Why or why not? \n",
    "\n",
    "Take a minute to explain. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA `.fit` result\n",
    "\n",
    "The output of `fit()` is a _transition_ matrix. This is the matrix that \"carries\" our data from a higher dimension down to the lower one. What `.fit` does **not** do is carry out this tranformation. For that step, we need to use `.transform()`. \n",
    "\n",
    "\n",
    "#### Using `.transform()`\n",
    "\n",
    "So far, we have set-up our PCA and applied it to our data to get our transition matrix. To actually send our data to the lower dimensional space, we _transform_ our data using `transform()`. \n",
    "\n",
    "\n",
    "_Note_ - Both `.predict` for kmeans and `transform` for PCA in `sklearn` are similar in the sense of _extending_ the common applications of their algorithms respectively. However, in the case of PCA, simply stopping at the _transition_ matrix feels a bit odd as the _dimension reduction_ has not yet occurred. To complete the dimension reduction, we use `transform()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "justnum_intwo = pca_alg.transform(justnum_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new lower dimensional result - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D plot of the new lower dimensional result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this what you expect given what you know about this data? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `fit_transform()` \n",
    "\n",
    "We can fit our PCA to our data and do the dimension reduction in one step using `fit_transform()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "justnum_intwo_onestep = pca_alg.fit_transform(justnum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a layer to compare the previous result to this one. \n",
    "# Your goal with this plot is to confirm that you have the same result\n",
    "\n",
    "# Create the plot from above with larger but fainter circles: \n",
    "plt.scatter(????, ????, s = 100, alpha = 0.5)\n",
    "# Layer with the new variable represented with little x markers\n",
    "plt.scatter(????, ????, marker = \"x\", c = 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside - `transform` is just matrix multiplication\n",
    "\n",
    "All that `.transform` is doing is _right_ multiplying our data with the transition matrix. In fact, if we define `trans_mat` as follows, we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat = pfit.components_\n",
    "justnum_intwo_mult = np.dot(justnum_std,trans_mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the shape is what we expect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a layer to compare the previous result to this one. \n",
    "# Your goal with this plot is to confirm that you have \n",
    "#      the same result using multiplication\n",
    "# Hint - It should look exactly like the above one, but \n",
    "#        with a different variable in the last line\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping up PCA \n",
    "\n",
    "Before moving on, apply PCA to `justnum_std` for 1, 3, and 4 components. Create visualizations for 1 and 3 dimensions. Considering the two dimensional ones that we created, what is the right number of components? **Justify** your choice. \n",
    "\n",
    "Below are a few code blocks for your experiments and plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait here for a class discussion** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the _lower_ dimension\n",
    "\n",
    "The goal of PCA is a dimension reduction. The question becomes how far should we reduce? What is the \"right\" lower dimension? After our adventure with k-means, it should come as no surprise that there is no universally accepted \"answer\" for choosing the right number for the lower dimension. If your primary reason for reducing the dimension is for data visualization, then many times the \"answer\" is 2 for the _target_ dimension. \n",
    "\n",
    "If your goal is to reduce your data to speed up algorithms or to simply remove redundant information, then you might look at how much your reduction _explains_ of the original data. Encapsulated in the `explained_variance_ratio_` is a notion of explanation. \n",
    "\n",
    "### Total Explained Variation \n",
    "\n",
    "Most data is spread out. Data that is more spread from each other with varying notions of \"near\" and \"far\", we call data of _high variance_ and by contrast data with _low variance_ is data that tends to be very tightly clustered together. The idea of _variance_ is to give us a notion of how spread (or not) our data is. It can also be thought of as a notion of the variation in between our data points. \n",
    "\n",
    "PCA seeks to be a summary of our original data. We want it to be a decent summary that gives us close approximation of the data. To give us an idea of how well our PCA works, we can compute how much of the original data's variation is _explained_ by each principal component. In `sklearn` this information is captured in `explained_variance_ratio_` or the ratio of the **total** variance that is explained by a particular component. \n",
    "\n",
    "The `explained_variance_ratio_` is an attribute of our fitted PCA. Compute PCA with four components and plot the `explained_variance_ratio_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_alg = PCA(n_components=4)\n",
    "pfit4 = pca_alg.fit(justnum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1f12cda0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pfit4.explained_variance_ratio_, marker='*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of components matches the dimension of the data, the sum of the `explained_variance_ratio_` should equal one. Check that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "# Your check here: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_ - If yours is not exactly one, check that the difference between your answer and 1 is below _machine tolerance_ or about $10^{-14}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "mach_tol = 10e-14\n",
    "print(np.abs(np.sum(pfit4.explained_variance_ratio_)-1) < mach_tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Take a minute to unpack what is in the second check. What does each piece do? Why are they so tightly wrapped?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `explained_variance_ratio_` to choose the \"right\" dimension\n",
    "\n",
    "In `explained_variance_ratio_` we have how much each principal component explains. As we can see above, the added benefit of each one goes down. This is related to the fact that the computation of `explained_variance_ratio_` has to do with the eigenvalues associated to each principal component (which by construction are in decreasing order). \n",
    "\n",
    "It would be much more helpful if we could see how much the cumulative contribution of the first component, the second component with the first, the third component with the first and the second, and so on. Now, while we could write a `for` loop, let's take a page out of our text _Python Machine Learning_ and use the numpy command `cumsum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_variance = np.cumsum(pfit4.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `cumsum()` takes cumulative sums in progressing order. To illustrate what this means run the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  6 10 15]\n"
     ]
    }
   ],
   "source": [
    "test_cumsum = np.cumsum([1,2,3,4,5])\n",
    "print(test_cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that that the first entry in the output is the value of the first index. The second entry is the sum of the the values associated to the first two indices, and so on. \n",
    "\n",
    "Returning to our cumulative variance, let's now plot this output against the individual contributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.step(range(1,5),cum_variance)\n",
    "plt.bar(range(1,5),pfit4.explained_variance_ratio_)\n",
    "\n",
    "# Plot based on image on Page 148 in _Python Machine Learning_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we should see in this plot is how much each piece contributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "SVD is linear algebra at its finest (though I promise not to explore that tangent). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity \n",
    "\n",
    "What is _sparse_ data? Is it bad or good? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated SVD\n",
    "\n",
    "There are a few flavors of SVD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA & SVD - A Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, read about the [PCA implementation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) in `sklearn` and create a post to **#lab_submission** channel on slack sharing one surprising thing about PCA that you learned by first walking through it and then reading about it in `sklearn`. Your post must start with **Lab6** to get credit. \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab6**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References consulted\n",
    "0. _Doing Data Science: Straight talk from the frontline_ by C. O'Neil & R. Schutt (2014)\n",
    "1. _Python Machine Learning_\n",
    "2. [PCA `sklearn` helpfile](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)\n",
    "3. [Truncated SVD `sklearn` helpfile](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD)\n",
    "4. [SVD `numpy` helpfile](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html)\n",
    "5. [What is principal component analysis? from \"Bits of DNA\"](https://liorpachter.wordpress.com/2014/05/26/what-is-principal-component-analysis/)\n",
    "6. [Explained variance in PCA](https://ro-che.info/articles/2017-12-11-pca-explained-variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
