{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 17\n",
    "\n",
    "Today, we will begin exploring the idea of _ensemble methods_ or methods that are an aggregate of several machine learning methods. Today, we will: \n",
    "\n",
    "0. Explain aggregation in terms of ensemble methods \n",
    "1. Look at how random forests work in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import seed\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image \n",
    "from pydot import graph_from_dot_data\n",
    "from six import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "Before we switch to the `sklearn` implementation, we will build an example random forest out of our from-scratch decision trees. Open Lab 16 and paste your from-scratch decision tree code below (along with all helper functions). Alternately, you can put all your functions from Lab 16 in a `Lab16.py` file and `import Lab16` in the import block above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from Lab 16\n",
    "\n",
    "def gini_index(data_pd: pd.DataFrame, class_var: str) -> float:\n",
    "    \"\"\"\n",
    "    Given the observations of a binary class and the name of the binary class column\n",
    "    calculate the gini index\n",
    "    \"\"\"\n",
    "    # count classes 0 and 1\n",
    "    count_A = np.sum(data_pd[class_var] == 0)\n",
    "    count_B = np.sum(data_pd[class_var])\n",
    "\n",
    "    # get the total observations\n",
    "    n = count_A + count_B\n",
    "\n",
    "    # If n is 0 then we return the lowest possible gini impurity\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Getting the probability to see each of the classes\n",
    "    p1 = count_A / n\n",
    "    p2 = count_B / n\n",
    "\n",
    "    # Calculating gini\n",
    "    gini = 1 - (p1 ** 2 + p2 ** 2)\n",
    "\n",
    "    # Returning the gini impurity\n",
    "    return gini\n",
    "\n",
    "def info_gain(data_pd: pd.DataFrame, class_var: str, feature: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates how much info we gain from a split compared to info at the current node\n",
    "    \"\"\"\n",
    "    # compute the base gini impurity (at the current node)\n",
    "    gini_base = gini_index(data_pd, class_var)\n",
    "\n",
    "    # split on the feature\n",
    "    node_left, node_right = split_bool(data_pd, feature)\n",
    "\n",
    "    # count datapoints in each split and the whole dataset\n",
    "    n_left = node_left.shape[0]\n",
    "    n_right = node_left.shape[0]\n",
    "    n = n_left + n_right\n",
    "\n",
    "    # get left and right gini index\n",
    "    gini_left = gini_index(node_left, class_var)\n",
    "    gini_right = gini_index(node_right, class_var)\n",
    "\n",
    "    # calculate weight for each node\n",
    "    # according to proportion of data it contains from parent node\n",
    "    w_left = n_left / n\n",
    "    w_right = n_right / n\n",
    "\n",
    "    # calculated weighted gini index\n",
    "    w_gini = w_left * gini_left + w_right * gini_right\n",
    "\n",
    "    # calculate the gain of this split\n",
    "    gini_gain = gini_base - w_gini\n",
    "\n",
    "    # return the best feature\n",
    "    return gini_gain\n",
    "\n",
    "def split_bool(data_pd, column_name):\n",
    "    \"\"\"Returns two pandas dataframes:\n",
    "    one where the specified variable is true,\n",
    "    and the other where the specified variable is false\"\"\"\n",
    "    pass\n",
    "\n",
    "def best_split(data_pd: pd.DataFrame, class_var: str, exclude_features: list = []) -> float:\n",
    "    \"\"\"\n",
    "    Returns the name of the best feature to split on at this node.\n",
    "    If the current node contains the most info (all splits lose information), return None.\n",
    "    EXCLUDE_FEATURES is the list of variables we want to omit from our list of choices\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def build_decision_tree(node_data: pd.DataFrame, class_var: str, depth: int = 0, exclude_features: list = []) -> None:\n",
    "    \"\"\"Build a decision tree for NODE_DATA with \n",
    "    CLASS_VAR as the variable that stores the class assignments. \n",
    "    EXCLUDE_FEATURES is the list of variables we want to omit from our list of choices\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "In this lab, we will continue working with the binary and full dog breed datasets from last lab. As a reminder, in the binary dataset, we have the following features:\n",
    "\n",
    "* Easy To Train\n",
    "* Kid-Friendly\n",
    "* High-Energy\n",
    "* Good For Novice Owners\n",
    "\n",
    "In the full dataset, we have additional numeric and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Binary Dog Data from Lab 16\n",
    "\n",
    "dog_pd = pd.read_csv(\"lab16data-binary.csv\", sep = \",\", index_col = \"Breed Name\")\n",
    "\n",
    "# If the above line does not work, move the Lab 16 data into Lab 17 folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for viewing imported data\n",
    "dog_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "**Ensemble methods** are methods that use an \"ensemble\" (or group) of methods to perform a task. In the ensemble method set-up, we run the various methods individually and then use some sort of aggregation of all of their results to return one result. \n",
    "\n",
    "For example, we might want to do a classification task assigning Smith students to houses (training on data from a previous class of students). We might try 1-NN, 3-NN, and a 5-NN to assign the house for a student, and get Haven-Wesley twice and Tyler once. What house would you assign this student to? _Why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to push your thinking a bit, consider that the results were:\n",
    "* **Situation 1** - Haven-Wesley (result from 1-NN), Haven-Wesley (result from 3-NN), and Tyler (result from 5-NN)\n",
    "* **Situation 2** - Haven-Wesley (result from 1-NN), Tyler (result from 3-NN), and Haven-Wesley (result from 5-NN)\n",
    "* **Situation 3** - Tyler (result from 1-NN), Haven-Wesley (result from 3-NN), and Haven-Wesley (result from 5-NN)\n",
    "\n",
    "For each of these situations, how would you assign this student to a particular house? \n",
    "* **Situation 1** - **Your Answer**\n",
    "* **Situation 2** - **Your Answer**\n",
    "* **Situation 3** - **Your Answer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the Ensemble\n",
    "\n",
    "Typically, we use **majority vote** to decide the ultimate classifier assigned by an ensemble method, but we can also develop (or tune) other kinds of voting systems, including weighted votes. (You can also \"tune\" this weighting as part of your supervised learning, but that is beyond the scope of this lab.)\n",
    "\n",
    "In the above example, under simple majority vote, all the situations would assign the student to Haven-Wesley. But if one used a weighted voting scheme that more heavily weighted the 5-NN, then it is possible that the student would be assigned to Tyler, instead. \n",
    "\n",
    "In this example, we used three different values of $k$ for our ensemble method. We also could have built several 3-NN classifiers, each with a different set of training examples, or each with a subset of all the features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Building A Grove of Trees\n",
    "\n",
    "In the above example, we used several versions of kNN and then performed some kind of voting system. We can do a similar thing with decision trees by creating multiple trees, then taking the majority vote of an observation's classification from each tree.\n",
    "\n",
    "We call an ensemble of trees a *grove*, and this grove of trees is the basis of random forest classifiers.\n",
    "\n",
    "Using your `build_decision_tree()` function from Lab 16, build three trees on the binary dog breed dataset (`dog_pd`) to predict the class \"Good For Novice Owners\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 1\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 2\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 3\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But wait... these are all the same tree!*\n",
    "\n",
    "In order to have different trees in our grove, we need to add some element of *randomness* to our tree building. Following our ideas from above, we could:\n",
    "* select a different random subset of the data as a training set for each tree, and/or\n",
    "* select a different random subset of the *features of the data* as possible decisions for each tree\n",
    "\n",
    "If we select a different random subset of the data as a training set for each tree, we may see some small variation in our tree structure. However, if we see large differences in our trees depending on the training data, we may be concerned that our trees are overfitting to each training dataset. Additionally, if one feature is much more impactful as a predictor of our classes compared to the other features, we may always split on that feature first—the feature acts as a bit of a **bully predictor** in determining tree shape.\n",
    "\n",
    "We can avoid bully predictors and enforce larger differences in tree structure in our grove by selecting a different random subset of the *features of the data* as possible decisions for each tree. For example, as we aim to predict \"Good For Novice Owners\" from our dog data, we could build our tree from any of these subsets of features:\n",
    "* \"Easy To Train\" and \"Kid-Friendly\", excluding \"High-Energy\"\n",
    "* \"Easy To Train\" and \"High-Energy\", excluding \"Kid-Friendly\"\n",
    "* \"Kid-Friendly\" and \"High-Energy\", excluding \"Easy To Train\"\n",
    "\n",
    "So far, we have observed that \"Kid-Friendly\" is usually the top decision in our tree. By excluding \"Kid-Friendly\" from at least one of our trees, we get to explore the effect of splitting on a different variable at the top of the tree. Exploring these different tree structures helps us avoid overfitting our trees to our data.\n",
    "\n",
    "Let's try building three trees again, this time excluding a different feature from each tree. (**Hint:** `build_decision_tree()` takes an optional parameter `exclude_features`, which is a list of features to omit from our list of potential decisions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 1: Excluding \"High-Energy\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=['High-Energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 2: Excluding \"Kid-Friendly\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", exclude_features=[???])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree 3: Excluding \"Easy To Train\"\n",
    "build_decision_tree(dog_pd, \"Good For Novice Owners\", ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which decision is at the top of each of your trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Thoughts Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Creating multiple trees from random subsets of the features in our dataset, rather than creating the same tree from all the features, helps us compare the effectiveness of splitting on certain features compared to others. For example, if we find that trees built when we exclude \"Kid-Friendly\" are less accurate classifiers, or that \"Kid-Friendly\" is usually at the top when we're allowed to consider that feature, then perhaps \"Kid-Friendly\" is an important variable in our trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Trees\n",
    "\n",
    "A major drawback of decision trees is that they tend to overfit to their training datasets. Think back to the giant tree at the end of Lab 16. Many of the leaves at the bottom of the tree contained small subsets of the data. If we were to build this same tree on multiple different samples of our dataset, the leaves of the trees might change substantially depending on which observations are included in each sample. However, the core structure of the tree (the top few decisions) would be more likely to remain the same.\n",
    "\n",
    "Returning to the idea of the bias-variance trade-off, we defined models which exhibit high _variance_ as models that if we were to change the data slightly or show the model new data, then the tree may change drastically. Models with high variance (ie. those that are overfit to the data) are said to be hard to generalize. They also might simply contain too many rules or decisions for assigning a label (or class) to a datapoint. In a sense, to avoid overfitting, we want nice compact trees where each node contributes more to the classification than the effort of adding that node to the tree.\n",
    "\n",
    "We avoid overfitting with decision trees by creating many **pruned** trees, where we cut off branches that don't contribute much to the tree. It is natural to ask why we are not just making short trees (ie. setting a `max_depth` parameter) instead of building a whole tree and then pruning? This is simply that we don't know what is useful until we have the _whole_ tree.\n",
    "\n",
    "Once we build a whole tree, we can prune off less important branches to get a tree with lower variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to `sklearn` for decision trees\n",
    "`sklearn` lets us prune decision trees using the `ccp_alpha` parameter. Larger values of this parameter result in more pruning of the decision tree. Since a tree on our binary dataset would be too small to prune meaningfully, let's launch into working with the full dataset from Lab 16.\n",
    "\n",
    "As a reminder, for this example, we are classifying whether a dog would be good for Novice owners or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import full dog data\n",
    "dog_full_pd = pd.read_csv(\"lab16data.csv\", sep = \",\", index_col = \"Breed Name\")\n",
    "dog_full_np = dog_full_pd.to_numpy(dtype = np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view full dog data\n",
    "dog_full_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into the input variables and the target classes\n",
    "in_dog_data = dog_full_np[:,:-1]\n",
    "out_class = dog_full_np[:,-1]\n",
    "\n",
    "# Get the variable names \n",
    "var_names = list(dog_full_pd.columns)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Pruned Trees\n",
    "\n",
    "Now, let's build three pruned decision trees using `sklearn`, setting the `ccp_alpha` parameter to 0.001, 0.01, and 0.1, and visualize each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare three decision tree classifiers, with alphas {0.1, 0.01, 0.001}\n",
    "dt1 = DecisionTreeClassifier(ccp_alpha = 0.001)\n",
    "dt2 = DecisionTreeClassifier(ccp_alpha = 0.01)\n",
    "dt3 = DecisionTreeClassifier(ccp_alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train three decision tree classifiers\n",
    "dt1.fit(in_dog_data, out_class)\n",
    "dt2.fit(in_dog_data, ???)\n",
    "dt3.fit(???, ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dt1 (ccp_alpha = 0.001)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dt1, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dt2 (ccp_alpha = 0.01)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(???, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph dt3 (ccp_alpha = 0.1)\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(???, out_file=dot_data, feature_names=var_names)\n",
    "(dt_vis, ) = graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(dt_vis.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which tree is overfit to the data? Which tree is underfit? What amount of pruning is about right for this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Thoughts Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Random Forest\n",
    "\n",
    "Now that we have developed more intuition about (1) taking a majority vote of multiple trees, (2) deciding among a random subset of our features to build different random trees, and (3) pruning large trees, we are ready to define random forests.\n",
    "\n",
    "Random forests classify data based on a **majority vote** of a grove of **pruned**, **random** decision trees.\n",
    "\n",
    "Let's build a grove of three pruned decision trees (pruning with the `ccp_alpha` parameter). We'll ensure we get a slightly different tree for each tree in the grove by setting the `max_features` to consider up 4 random features in each tree.\n",
    "\n",
    "To learn more about the parameters of `DecisionTreeClassifier`, see the [scikit-learn documentation for decision trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build three trees with the same criteria\n",
    "seed(2022)\n",
    "dt1 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)\n",
    "dt2 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)\n",
    "dt3 = DecisionTreeClassifier(max_features = 4, ccp_alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all three - due to randomness, will be different trees\n",
    "dt1.fit(in_dog_data, out_class)\n",
    "dt2.fit(in_dog_data, ???)\n",
    "dt3.fit(???, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we make any predictions, take a moment to remind yourself what we are trying to predict.   \n",
    "\n",
    "* What does it mean for a prediction to be 0? **Your thoughts**\n",
    "* What does it mean for a prediction to be 1? **Your thoughts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for the first ten dogs using the first classifier\n",
    "dt1.predict(in_dog_data[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for the first ten dogs using the second classifier\n",
    "dt2.predict(in_dog_data[???])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for the first ten dogs using the third classifier\n",
    "dt3.predict(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Choose a dog that not all three trees agreed on how to classify. What did each of the three random trees predict as the class for this dog? Based on a majority vote, how would we classify the dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests in `sklearn`\n",
    "\n",
    "Now, we'll build a random forest classifier using `sklearn`.\n",
    "\n",
    "Here we have a few parameters to unpack: \n",
    "* `n_estimators` means the number of trees in your grove\n",
    "* `max_features` means the number of features that the tree in your grove can use\n",
    "* `max_depth` means how many layers your trees have\n",
    "\n",
    "Note that pruning our trees is computationally expensive. When we build whole trees and prune them back, we potentially gain more information on which decisions are useful at many levels of our tree, but at the cost of much slower speed.\n",
    "\n",
    "If we have enough trees in our grove, it's often worth the tradeoff (of information vs. speed) to restrict the depth of our trees rather than building tall trees and pruning back. In practice, this means that `RandomForestClassifier` does have a `ccp_alpha` parameter to prune the trees, but we usually set a `max_depth` instead.\n",
    "\n",
    "**Question:** Where, in our prior work for this lab and thinking back to Lab 16, have we performed the equivalent of each of these three parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `n_estimators`: *(your answer here)*  \n",
    "* `max_features`: *(your answer here)*\n",
    "* `max_depth`: Our original stopping condition for our from-scratch decision tree in Lab 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first specify our random forest model, and then fit the random forest model to our data—very similar to the prior `sklearn` classifiers we have built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify our model\n",
    "grove = RandomForestClassifier(n_estimators=10, max_features=3, max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model to the data\n",
    "grove.fit(in_dog_data, ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences from our random forests\n",
    "\n",
    "We can use our random forest to tell us which features are the most important: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each importance in the list corresponds with a feature in the dataset\n",
    "# higher numbers are more important features\n",
    "print(list(dog_full_pd.columns[:-1]))\n",
    "print(grove.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the most important feature in the dataset? Which features are least important? Does this surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Thoughts Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make predictions for a certain dog (or set of dogs), such as for the Laborador Retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_traits = dog_full_pd.loc['Labrador Retriever'][:-1]\n",
    "## (why do we leave off the last feature?)\n",
    "\n",
    "lab_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grove.predict([lab_traits])\n",
    "## (why do we need extra brackets around our 1D data?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the true class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_full_pd.loc['Labrador Retriever'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did our system do for this **one** example? \n",
    "\n",
    "**Your thoughts here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how well we did on our training set (as an accuracy between 0 and 1). That is, we can see for all dog breeds used to create our random forest how well our model did predicting the correct class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grove.score(in_dog_data, out_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did our system do for the **whole** training set? Given this score, how well do you think it would do on a new dog breed? \n",
    "\n",
    "**Your thoughts** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn!\n",
    "\n",
    "Experiment a bit with `max_feature` and `max_depth` in `RandomForestClassifer` and build a second grove. Fit and evaluate this grove on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify our model\n",
    "grove2 = RandomForestClassifier(n_estimators=10, max_features=??, max_depth=??, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model to the data\n",
    "grove2.fit(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the accuracy on the training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "Similar to Lab 16, you have two choices for how you finish up this lab. To get credit, you only need to do one of the two choices. Note that Choice 2 is the same as in Lab 16. \n",
    "\n",
    "If you did **not** answer Choice 2 for Lab 16 (either because you chose Choice 1 or because you skipped Lab 16), please answer Choice 2 in this lab. If you have already answered Choice 2 from Lab 16, please answer Choice 1 in this lab.\n",
    "\n",
    "#### Option 1 - Final Questions:\n",
    "\n",
    "To finish up this lab, choose another dog breed from the dataset and then ask `grove2` to `predict` whether the breed is \"Good For Novice Owners.\" Share your dog breed, what `grove2` predicted, and the actual classification. Optionally, if you have experience with this dog breed, share your own thoughts on the breed's classification. Then answer the question: **Do you think that random forests are an improvement over the decision tree from last lab?** Why or why not?\n",
    "\n",
    "#### Choice 2 - Final Questions:\n",
    "\n",
    "1. Explain at least one scenario in which use of this classifier could be potentially harmful.\n",
    "2. Name at least one other scenario where forming decisions via a classifier could be potentially harmful and/or unethical. Explain why.\n",
    "3. What are some considerations you would want to keep in mind when deciding whether use of a classifier is appropriate in a given scenario?\n",
    "\n",
    "Share your thoughts in a post on the **#lab17_submission** channel on Slack.\n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab17**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. [ISLR](https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6062a083acbfe82c7195b27d/1617076404560/ISLR%2BSeventh%2BPrinting.pdf) Section 8.2\n",
    "1. [SDS 293 Notes by R. Jordan Crouser](http://www.science.smith.edu/~jcrouser/SDS293/)\n",
    "2. [Random Forest in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "3. [Decision Tree in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "4. [Post pruning decision trees in sklearn](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
