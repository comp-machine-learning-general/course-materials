{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14\n",
    "\n",
    "Today, we will start exploring another method for classification **_Support Vector Machines_** or SVM. Before we dig into SVMs, we will start with how to evaluate classification results. Today's goals are: \n",
    "\n",
    "0. Explain how to evaluate models in the classification task\n",
    "1. Define Maximal Margin\n",
    "2. Motivate SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on Cross Val\n",
    "\n",
    "Before starting with today's topics, let's talk about cross val. Consider two questions: \n",
    "* Which is better: $k$-fold or LOOCV? Why? \n",
    "* Is there a comparison to the _process_ of cross val to gradient descent (ie. mini-batch and stochastic)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Methods for Classification \n",
    "\n",
    "Classification and prediction are often seen as two different and distinct parts of supervised machine learning. One of the biggests differences has to do with the notion of \"close\". In prediction, a model can be _close_ but not exactly on truth to be considered \"good enough.\" However for classification, we are placing objects into distinct groups and there is no notion of \"close enough.\" For example, one either plays for the Washington Nationals or they don't. In professional baseball, there is no notion of playing part time for two teams. \n",
    "\n",
    "With this difference in mind, how do we evaluate our methods for classification tasks? Let's start with a specific evaluation metric MSE and adjust this for classification. We begin by recalling the equation for MSE for prediction:\n",
    "\n",
    "\\begin{equation}\n",
    "MSE_{\\textrm{prediction}} = avg(||truth-guess||^2)\n",
    "\\end{equation}\n",
    "\n",
    "In classification, we have _predicted classes_ and the _true classes_ of each data point. How might we adjust the above for classification? \n",
    "\n",
    "Take a minute to jot down your thoughts and we'll come back together to discuss: \n",
    "\n",
    "\\begin{equation}\n",
    "MSE_{\\textrm{classification}} = \\textbf{????}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   \n",
    "#   \n",
    "#   \n",
    "#     \n",
    "\n",
    "(this area is intentionally left blank)\n",
    "\n",
    "#   \n",
    "#   \n",
    "#   \n",
    "#     \n",
    "#   \n",
    "#   \n",
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator functions\n",
    "\n",
    "One trick that we use in machine learning over and over again are **indicator functions**. Simply indicator functions _indicate_ something. We often use them in a similar way to boolean functions. With an indicator function, we _indicate_ that a condition is met with a 1 and if not, the indicator function results in a 0. We write indicator functions as: $I(\\textrm{condition})$. \n",
    "\n",
    "For example, we can reimagine MSE as the average of the indicator function over the whole function, where the indicator function indicates when the true class does not equal the predicted class: \n",
    "\n",
    "\\begin{equation}\n",
    "MSE_{\\textrm{classification}} = avg(I(true class \\neq pred class))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is this related to MSE for prediction?!?\n",
    "\n",
    "In the case of classification, we are either correct or not. So in this MSE, we want to know the average number of times that we are wrong. So we add up all the times that we are wrong (using the indicator function) and divide by the total number of datapoints. \n",
    "\n",
    "This is very similar to the MSE for prediction (ie. linear regression) where we added up how off we were (squared) and divided by the number of data points.\n",
    "\n",
    "(Thank you to a previous ML explorer for asking about this connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating SVM \n",
    "\n",
    "Today, we are going to start looking at Support Vector Machines (or SVMs). SVM is a method for classification. As with kNN, we will work on examples that split our data into two classes. \n",
    "\n",
    "Last week, we focused on the motivating the differences between the train and test phases in supervised learning from the perspective of reaching for the truth underlying our data. In classification, we can use the same lens; we are seeking not to just divide the data that we have into two groups, but rather to **find the true boundary** that exists between the territory of the two groups. For example, instead of just trying to classify people into what state they live in based on their location, can we use the locations of where people live to find the state boundaries? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Today\n",
    "\n",
    "Today we are working with two new (constructed) datasets. \n",
    "\n",
    "We begin as usual, importing the packages and data that we need. Plot the first dataset `new_data` and note at least 2 observations about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import block\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "\n",
    "import random \n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for later use\n",
    "\n",
    "def assign_class(datapoint, slope, intercept):\n",
    "    pass\n",
    "\n",
    "def classification_mse(class_truth, pred_class):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For function testing \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "\n",
    "new_data = pd.read_csv(\"lab14data.csv\", sep = \",\")\n",
    "new_data_np = np.genfromtxt(\"lab14data.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "extra_data = pd.read_csv(\"extra_lab14data.csv\", sep = \",\")\n",
    "extra_data_np = np.genfromtxt(\"extra_lab14data.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "## x-values for plotting\n",
    "x = np.linspace(-3.1,3.15,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new_data\n",
    "#\n",
    "# What do you notice? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example boundaries \n",
    "\n",
    "With the goal of dividing the space into two territories. Which of the below options do you think is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible boundaries:\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"])\n",
    "\n",
    "# Plot one possible option to divide the two groups\n",
    "# In this case y = 0.6x\n",
    "plt.plot(x,0.6*x,linestyle='dashed',c=\"r\")\n",
    "\n",
    "# Plot another possible option to divide the two groups: \n",
    "# In this case y = 1.6x\n",
    "plt.plot(x,1.6*x,linestyle='dashed',c=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** - What do you like about each of these lines? Is one better than another? \n",
    "\n",
    "(Notes for you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider one more option: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"])\n",
    "\n",
    "# Plot a third possible option to divide the two groups: \n",
    "# In this case y = x\n",
    "plt.plot(x,x,linestyle='dashed',c=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** - What do you like about this line? Is this one better than the others? \n",
    "\n",
    "(Notes for you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximal Margin\n",
    "\n",
    "Recall that our goal is dividing a data space into two \"territories.\" We don't know how much noise exists in our dataset, and so we want to consider which line would create the widest boundary between our two data groups. \n",
    "\n",
    "I think of this as _how much can we inflate a line before the inflated line touches the data._ To visualize this idea, we will use the method `fill_between`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inflating the red boundary:\n",
    "inflate_width = 0.7\n",
    "\n",
    "# Plot the data points \n",
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"])\n",
    "\n",
    "# Plot the boundary \n",
    "plt.plot(x,0.6*x,'-r')\n",
    "\n",
    "#Plot the \"inflation\" around the line\n",
    "plt.fill_between(x, 0.6*x - inflate_width, 0.6*x + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this margin touch/include any data points? \n",
    "\n",
    "Play with the `inflate_width` variable above to find a good value for this parameter that is as big as possible without touching the data. \n",
    "\n",
    "Repeat this process for the green and black lines below. According to your experiments, which has the widest possible inflation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inflating the green boundary:\n",
    "inflate_width = ?????\n",
    "\n",
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"])\n",
    "plt.plot(x,1.6*x,'-g')\n",
    "plt.fill_between(x, 1.6*x - inflate_width, 1.6*x + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inflating the green boundary:\n",
    "inflate_width = ?????\n",
    "\n",
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"])\n",
    "plt.plot(x,x,'-k')\n",
    "plt.fill_between(x, x - inflate_width, x + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal Margin Defintion\n",
    "\n",
    "The maximal margin is simply the biggest margin that we can place **between** our two groups. We build this margin by finding a central line and then inflating it equally in both directions. Finding this central line uses Lagrange multipliers, which while really cool, are beyond the scope of this course. \n",
    "\n",
    "We can define the maximal margin for higher dimensions beginning with a plane (or hyperplane) and inflating it in the same manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Maximal Margins\n",
    "\n",
    "It turns out that we have a bit of extra data, and true to the train/test paradigm, let's see how our best line does with this extra data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "plt.scatter(new_data[\"myst\"],new_data[\"mysty\"], \n",
    "            c=new_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "# Testing data\n",
    "plt.scatter(extra_data[\"myst\"],extra_data[\"mysty\"], \n",
    "            c=extra_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "## Your line and inflated part here - \n",
    "# You need to fill in which line r (y = 0.6x), g (y = 1.6x), \n",
    "# k (y = x) is the best one based on your thoughts from above\n",
    "inflate_width = ???\n",
    "plt.plot(x, ???, '-?') \n",
    "plt.fill_between(x, ??? - inflate_width, ??? + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violations to the Margin\n",
    "\n",
    "Notice that we have some colors on the wrong side of the line. This tells use that perhaps our margin does not generalize to new data very well. Let's count how well it did on **just** the test data. \n",
    "\n",
    "The below plot plots only the test datapoints with the decision boundary and the associated inflated part. Using the below plot:\n",
    "* Count how many data points are on the wrong \"side\" of the line\n",
    "* Count how many data points are on the right \"side\" of the line BUT are within the margin\n",
    "\n",
    "Both of these are violations to the maximal margin, but of different intensities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting violations\n",
    "\n",
    "# Testing data\n",
    "plt.scatter(extra_data[\"myst\"],extra_data[\"mysty\"], \n",
    "            c=extra_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "## Your line and inflated part here - \n",
    "# Again, please fill in which line r (y = 0.6x), g (y = 1.6x), \n",
    "# or k (y = x) is the best one based on your thoughts from above\n",
    "inflate_width = ???\n",
    "plt.plot(x, 1.6*x, '-?') \n",
    "plt.fill_between(x, ??? - inflate_width, ??? + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Given these counts and this plot, do you think this is a good margin? \n",
    "\n",
    "(Notes for you)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can you alter the width of the margin to have less violations within the margin? (Try this below.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the margin width \n",
    "\n",
    "# Testing data\n",
    "plt.scatter(extra_data[\"myst\"],extra_data[\"mysty\"], \n",
    "            c=extra_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "## Your line and inflated part here - \n",
    "# Again, please fill in which line r (y = 0.6x), g (y = 1.6x), \n",
    "# or k (y = x) is the best one based on your thoughts from above\n",
    "inflate_width = ???\n",
    "plt.plot(x, ???, '-?') \n",
    "plt.fill_between(x, ??? - inflate_width, ??? + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying other boundaries\n",
    "\n",
    "Returning to our other examples from earlier, is either of the other two options a \"better\" margin? In other words, if we use either of the other lines as the boundary, can we have a wider margin with the same (or fewer) violations in the test set? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the margin width for a first other option \n",
    "\n",
    "# You used one option for the line above, choose a different \n",
    "# one from our list: r (y = 0.6x), g (y = 1.6x), or k (y = x) \n",
    "# as the second one that you will explore. \n",
    "\n",
    "# Vary margin (ie. inflate_width) and count the violations: \n",
    "\n",
    "# Testing data\n",
    "plt.scatter(extra_data[\"myst\"],extra_data[\"mysty\"], \n",
    "            c=extra_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "## Your line and inflated part here - \n",
    "inflate_width = ???\n",
    "plt.plot(x, ???, '-?') \n",
    "plt.fill_between(x, ??? - inflate_width, ??? + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the margin width for second other option \n",
    "\n",
    "# You have used two options for the lines above. Now select  \n",
    "# the last one from our list: r (y = 0.6x), g (y = 1.6x), \n",
    "# or k (y = x) to explore. \n",
    "\n",
    "# Vary margin (ie. inflate_width) and count the violations: \n",
    "\n",
    "# Testing data\n",
    "plt.scatter(extra_data[\"myst\"],extra_data[\"mysty\"], \n",
    "            c=extra_data[\"group\"], cmap = \"spring\")\n",
    "\n",
    "## Your line and inflated part here - \n",
    "inflate_width = ???\n",
    "plt.plot(x, ???, '-?') \n",
    "plt.fill_between(x, ??? - inflate_width, ??? + inflate_width, \n",
    "                 edgecolor='none', color='#AAAAAA', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Margin?\n",
    "\n",
    "Which one is the best? What makes you say that? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In this exploration we have used the _test_ set to inform our discussion about which is the \"best\" margin. We did this for the purpose of _motivating_ SVM. In the usual set-up, the test set would **not** be involved with deciding the maximal margin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximal Margins --> SVM \n",
    "\n",
    "SVM is _**relaxation**_ of the maximal margin. Recall that maximal margins are between two classes, which means that they do not allow for any violations, either in the margin or crossing the middle boundary. In SVM, we seek to balance 1) finding the widest margin and 2) allowing (but limiting) violations to the boundary. \n",
    "\n",
    "For SVM, we follow the usual procedure for supervised learning. We first divide our data into training and testing data. Then we find the best margin based on the training data and evaluate how well it did on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning classes\n",
    "\n",
    "In preparation for implementing SVM, we create a function that assigns each data point to a class based on it's relationship to the boundary line. If the datapoint is above the boundary assign it to class `1` (the positive class) and if it is below assign it to class `-1` (the negative class). \n",
    "\n",
    "**Relationship to the boundary** - To determine whether a point is above or below the boundary, we follow the below procedure:    \n",
    "1. Convert our boundary line from an equation (like $y = mx + b$) to an expression (such as $y - (mx + b)$).    \n",
    "2. Create relationship function $\\textit{R}(p)$ as being equal to this expression. That is for a point $p = (p_x,p_y)$, then $\\textit{R}(p) = p_y - (m\\cdot p_x + b)$.   \n",
    "3. Define a classification function $C(p)$ such that if $\\textit{R}(p) \\ge 0$, then $C(p) = 1$. Otherwise $C(p) = -1$. In effect $\\textit{R}(p)$ tells us whether our point $p$ belongs to the positive or negative class. \n",
    "\n",
    "At the top of this notebook, there is a beginning for the function above called `assign_class` that seeks to assign points to the positive and negative classes. Use the above outline to fill in the details for `assign_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next time\n",
    "\n",
    "Next time, we will implement SVM and discuss how **kernals** are central to SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, complete definitions for `assign_class` and `classification_mse`. Test your implementations on the three potential lines from this lab by computing the classification test MSE for each of them. \n",
    "\n",
    "Then apply your implementation to a new line of your choosing. Make a plot with the line of your choosing and state the classification test MSE. Is your new line a good one? Justify your answer with both a picture and the classification test MSE. Share your plot and your answer in a post on **#lab14_submission** channel on slack with your answer. \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab14**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted \n",
    "\n",
    "0. [ISLR](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)\n",
    "1. [SDS 293 Notes by R. Jordan Crouser](http://www.science.smith.edu/~jcrouser/SDS293/)\n",
    "2. [In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
