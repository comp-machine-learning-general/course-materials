{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "\n",
    "The next two labs concern developing the language around machine learning as well as an intuition for how these words are used. Today we will examine _prediction_ which, like classification, is a classic supervised learning task. Today's goals are:\n",
    "\n",
    "0. Goal 0 \n",
    "1. Goal 1\n",
    "2. Goal 2 \n",
    "3. Goal 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import block\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "In prediction, we aim to guess the output value given a set of input variables. In fact you've been doing \"supervised\" learning in many classes: linear regression. \n",
    "\n",
    "In its simpliest form, linear regression takes an input value $x$ and returns a value for $y$ using the formula $y = mx + b$, for some value of $m$ and some value of $b$. How do we find the values for $m$ and $b$? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Today's (fake) data\n",
    "\n",
    "For today, we are using another artifically created dataset based on [this example](https://paulvanderlaken.com/2017/09/27/simpsons-paradox-two-hr-examples-with-r-code/). \n",
    "\n",
    "In this example, we are consulting for _FakeData Inc_ and our job is to assist them in better understanding their employees. The CEO read an article that claimed that the higher a person's neuroticism score from the [Big Five personality](https://en.wikipedia.org/wiki/Big_Five_personality_traits) test the better their performance at work is, and the higher the person's salary is. \n",
    "\n",
    "So the CEO has directed us to develop an algorithm that predicts a person's performance score asl well as their salary based on their neuroticism score. \n",
    "\n",
    "\n",
    "Please import the data and check the shape of the data, but do **not** plot it _yet._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with Two points\n",
    "\n",
    "Let's start with two people that a manager at _FakeData Inc_ says are representative of many employees.\n",
    "\n",
    "Based on this information, find the values for $m$ and $b$ for the simple linear regression. Then plot these two points with the associated line for the create a line for these points. \n",
    "\n",
    "\n",
    "### Simple Linear regression in `sklearn`\n",
    "\n",
    "Unlike our usual procedure of building from scratch, we're going to just use the off the shelf `sklearn` implemenation for the linear regression. If you would like to better understand the theory for how and why this works, check out SDS 291 for all the details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the particulars for the linear regression\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the linear regression to the data\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "# Extract the coefficients\n",
    "m = lm.coef_[0]\n",
    "b = lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the points \n",
    "\n",
    "# Plotting your particular model/guessing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have another person who has a score of 7. Given your line, what do you expect their performance score to be? \n",
    "\n",
    "We have their perfomance score; it is Y. Does this surprise you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequence of steps follows the general process of **supervised** learning:\n",
    "0. Decide what task we are doing (classification or prediction) and selet the algorithm/model we want to use\n",
    "1. Using part of the available data with their given outputs, fit algorithm/model\n",
    "2. Check the model against \"new\" data (ie. the data that we did **not** use in the fitting). Use the \"truth\" to evaluate the \"goodness\" of the model. \n",
    "\n",
    "In our example, we did these as follows:\n",
    "0. Decided to do _prediction_ using _simple linear regression_\n",
    "1. Used (input score, performance score) of two points to determine the $m$ and the $b$ for the simple linear regression. \n",
    "3. Made a prediction for a new person using only their input value and checked it against the true performance score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervision\n",
    "\n",
    "The _supervision_ occurs in the Step 1, where we use the \"answers\" to help us set where the line should be. Without these answers/output/response variables, we could place a line in an number of places, but those placements would have nearly nothing to do with our goal of _predicting_ the performance score from the _whatever_ score. In prediction, we are seeking a model that is directly tied to _answer_ and as such we must use it as part of fitting the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this sequence compare or contrast to _unsupervised learning_ where there is no supervision. Below are two outlines, one for general and one for a particular $k$-means example. Be sure to note where the supervision is _lacking_ in the general case, and then pick one such example to make the list of general steps more concrete. \n",
    "\n",
    "This sequence of steps follows the general process of supervised learning:\n",
    "0. Decide what task we are doing (**option 1** or **option 2**) and selet the algorithm/model we want to use\n",
    "1. **Fitting step**\n",
    "2. **Evaluating step**\n",
    "\n",
    "In our example, we did these as follows:\n",
    "0. Specific Step 0\n",
    "1. Specific Step 1\n",
    "2. Specific Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait here for a class discussion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, select one of the values of $k$ and follow the [Nearest Neighbors Classification example for `sklearn`](https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py) to create a plot of the decision boundaries for kNN with your value of $k$. Share your plot in a post on **#lab_submission** channel on slack and share something that surprised you about your plot. Your post must start with **Lab7** to get credit. \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab7**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References consulted\n",
    "0. _Doing Data Science: Straight talk from the frontline_ by C. O'Neil & R. Schutt (2014)\n",
    "1. _Python Machine Learning_\n",
    "2. [Simple and Multiple Linear Regression in Python](https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9)\n",
    "3. [Simple Line Plots](https://jakevdp.github.io/PythonDataScienceHandbook/04.01-simple-line-plots.html)\n",
    "3. [Simpson’s Paradox: Two HR examples with R code.](https://paulvanderlaken.com/2017/09/27/simpsons-paradox-two-hr-examples-with-r-code/)\n",
    "4. [Simpson’s Paradox data](https://itsalocke.com/datasaurus/reference/simpsons_paradox)\n",
    "5. [Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing](https://www.autodeskresearch.com/publications/samestats) <= making dino data\n",
    "6. [Simpson’s Paradox and Interpreting Data](https://towardsdatascience.com/simpsons-paradox-and-interpreting-data-6a0443516765)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
