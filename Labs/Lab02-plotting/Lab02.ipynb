{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "After Lab 1, you should be able to import data, be able to determine a few quick facts about that data, and articulate the purpose of unit testing. Today we going to extend on our work from last time. Our goals are to:\n",
    "1. Use GitHubActions for Continuous Integration\n",
    "2. Use `pandas` to select parts of data, and \n",
    "3. Use `matplotlib`, `pandas`, and `seaborn` to make images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before starting...\n",
    "\n",
    "A few questions before we begin:\n",
    "* Do you need to `pull` anything? \n",
    "* Do you need to copy anything into a folder? \n",
    "* Are you in the right `env`ironment? \n",
    "\n",
    "<sub>These reminders will smaller and smaller as we get used to the flow of this course.</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous integration with GitHubActions\n",
    "\n",
    "In Lab 1, we learned about unit testing. We were able to create and locally run our \n",
    "unit tests. Now we will shift to using GitHubActions to continuously test our code against \n",
    "the unit tests. Continually testing our code with each push is called \n",
    "**continuous integration** or CI.\n",
    "\n",
    "For this part, I have created [an assignment](https://classroom.github.com/a/NyqhDReW) \n",
    "called `Lab02-GitHubActions`. Just as you did for Lab 0, please click on this link and \n",
    "create your own local repository. In this repo, you will find three files:\n",
    "1. `.gitignore`, and \n",
    "2. `requirements.txt`\n",
    "\n",
    "Add your two python files from lab 1 (not the jupyter notebooks) and the data file to \n",
    "this directory. Commit your changes. \n",
    "\n",
    "The next steps are the written out version of this video on Panapto. You are welcome to \n",
    "use just one or both as you navigate creating your continuous integration (CI) workflow. \n",
    "\n",
    "Now we need to create a testing action on  your repository on GitHub:\n",
    "1. Visit your personal `Lab02-GitHubActions` repo on GitHub. \n",
    "2. At the top of the repo, you will see the usual menu bar: *Code*, *Issues*, *Pull Requests*, \n",
    "*Actions*, etc. Click on **Actions** \n",
    "3. GitHub is going to try guess which kind of action you would like. You are looking for the \n",
    "**\"Python Application\"** choice under **\"Continuous integration.\"** When you find that \n",
    "one, click **Configure**\n",
    "4. The next screen will be a YAML file called `python-app.yml` inside a newly created hidden \n",
    "directory called `.github/workflows/`. This `.yml` file tells GitHub Actions how we want these \n",
    "tests to run. We are going to make a few edits to this file. First delete all references to \n",
    "`flake8`. This happens first on line 26 and then lines 28-33. \n",
    "5. Then click on **Start commit.** You can commit right to `main`. (In the video, I add a bit to \n",
    "the messages associated with the commit, but you are fine to leave that as is.) Then click \n",
    "**commit new file.**\n",
    "6. Now you are back in the newly created hidden directory `.github/workflows/` and you should \n",
    "see your `.yml` file there. \n",
    "7. Now click *Actions* again. You should see a header **All workflows** and under that your \n",
    "commit message with a <font color='yellow'>**Yellow**</font> dot next to it. \n",
    "    \n",
    "GitHub Actions uses color to tell you want is happening:    \n",
    "* <font color='yellow'>**Yellow**</font> means that GitHub Actions is thinking   \n",
    "* <font color='red'>**Red**</font> means that either the build or the tests have failed   \n",
    "* <font color='green'>**Green**</font> means that the build and the tests have worked!    \n",
    "\n",
    "Two notes: \n",
    "* For GitHub Actions to \"build\" things correctly, you will need to have both `requirements.txt` and an \n",
    "associated `.yml`. \n",
    "* Also as noted in [Part 5](https://bmcfee.github.io/ismir2018-oss-tutorial/tutorial/2018/08/12/part-5.html) \n",
    "of McFee and Kell's Open MIR Tutorial, it is unlikely that your tests will pass locally, but fall on \n",
    "GitHubActions. When this happens it is usally due to a difference between your local machine's set-up \n",
    "and what you `require` (via `requirements.txt`) for the virtual environment. \n",
    "\n",
    "For homework 1, you will need to submit green boxes showing that you have correctly linked your \n",
    "repo to GitHubActions  and that your tests pass. \n",
    "  \n",
    "  \n",
    "#### Resources consulted \n",
    "  \n",
    "Including continuous integration (CI) in this course was motivated by \n",
    "[Part 5](https://bmcfee.github.io/ismir2018-oss-tutorial/tutorial/2018/08/12/part-5.html) of McFee \n",
    "and Kell's Open MIR Tutorial. Their tutorial used Travis, which was one of the most popular CI \n",
    "platforms at the time. This is not longer the case, which is why we are not using travis. \n",
    "\n",
    "This text was adapted from the original (travis-based) Lab 2, which was adapted from \n",
    "[Part 5](https://bmcfee.github.io/ismir2018-oss-tutorial/tutorial/2018/08/12/part-5.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to code today\n",
    "\n",
    "We need an extra package today: `seaborn`. If you run into issues (such as `not found` or other errors), please use `conda` to add this to your environment. (Also, double check that you are in your `csc294` environment! This one always gets me.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting subsets with `pandas`\n",
    "\n",
    "In Lab 1, we learned about data frame structure within `pandas` and for class today, you read about some of the functionalities of `pandas`. Today, we will practice various kinds of slicing and how we can create new dataframes from previous ones.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing the Forest Fires dataset from Lab 0 and reminding ourselves of what the first 5 rows look like. Add the `forestfire` file to the directory that you are using to work on Lab 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire = pd.read_csv(\"forestfires.csv\", sep=',')\n",
    "ffire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a small snapshot of our data. Before moving on, what do you think the **bold** means? (Make a few notes below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas` we can select slices of our data either by row or by column using either the names or counters. \n",
    "\n",
    "### Selecting by Row\n",
    "\n",
    "The two most common ways to access rows are by using `.loc` and `.iloc`, which stand for [_location_](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) and [_index location_](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html), respectively. \n",
    "\n",
    "In this data, the names of the row indices are the same as the counter. So we will find that we can access each row in _nearly_ identical ways. Note that this is quite _**unusual**_. \n",
    "\n",
    "The general format for `loc` and `iloc` is row information first, followed by column selections (if desired). Try the below examples and note 1) how they are different and 2) what the arguments are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[2,'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[[0,2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[0:5,'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[0:5,['month', 'wind', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[[0,2,5],['month', 'wind', 'day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**!!!! `.loc` does not slice in the usual manner for `python`. Notice that the last index is _included_. This is very unusual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have just used `.loc`. Repeat all the above examples using `.iloc`; do they all work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for you!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big difference between `.loc` and `.iloc` is that the first expects the index _names_ for both the rows and the columns, while the second expects the index _numbers_. So to make `.iloc` work, we need to have the index number for each column. Try again below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for you!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by Column\n",
    "\n",
    "Extending the ideas from before, we can extend the ideas from above using `.loc` and `.iloc`, to get the full columns (ie. all the rows). How might you do this? Experiment with the two below blocks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.loc[?????,['month', 'wind', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.iloc[?????,[2,10,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to access the columns uses `[]` to do our slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire[['month', 'wind', 'day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Experiment with selecting different parts of the forest fire dataset in the below code block. \n",
    "\n",
    "Also, note that this is just the beginning of what we can do with `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for you!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with `matplotlib`\n",
    "\n",
    "For this course, most of our visualizations will be built using `matplotlib`. There is another language called MATLAB which can be used for scientific computing (of largely numerical data). MATLAB is optimized for matrix and vector operations, but unlike python, it is not freely available. Along with its powerful computational tools, MATLAB can create data-based images. As the transition away from MATLAB and towards python began, there was a need for all the functionality of MATLAB to exist within python. So the creation and popularity of `matplotlib` makes a lot of historical sense. \n",
    "\n",
    "In this section, we will just begin to scratch the surface of what `matplotlib` can do. This section of the lab is based on Chapter 9 of _Python for Data Analysis_ applied to the [forest fires dataset](http://archive.ics.uci.edu/ml/datasets/Forest+Fires). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing `matplotlib`\n",
    "\n",
    "You might notice three new lines in our import block.\n",
    "1. `%matplotlib inline` allows our plots to show up inline within our jupyter notebook    \n",
    "   Note - This **must** come before importing _matplotlib_\n",
    "2. `import matplotlib.pyplot as plt` imports the plotting part of _matplotlib_\n",
    "3. `import seaborn as sns` imports _seaborn_ for our plots using _pandas_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For this first part, we will import our forest fire data as a `numpy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import forest fire data as a numpy array\n",
    "\n",
    "ffire_np = np.genfromtxt(\"forestfires.csv\",delimiter=\",\",skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First plot\n",
    "\n",
    "In `jupyter` we have to do everything for our plots in one code block. So I will be adding comments within the next code block to explain each line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "# In MATLAB, as in `matplotlib`, plots exist within Figure objects.\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create each of the subplots in their locations\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "\n",
    "# Plot the wind column in order by the rows\n",
    "# Q1: Where is this plot placed? \n",
    "# Q2: Would it stay there if you changed the order of the 'ax' lines?\n",
    "plt.plot(ffire_np[:,10], \"k--\")\n",
    "\n",
    "# Create a histogram of the wind information\n",
    "_ = ax1.hist(ffire_np[:,10], bins=10, color=\"b\", alpha = 0.3)\n",
    "\n",
    "# Create a scatter plot of the X and Y columns\n",
    "ax2.scatter(ffire_np[:,0], ffire_np[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn! \n",
    "\n",
    "Make a `matplotlib` plot of the forest fire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot that `matplotlib` can do, as seen in the [matplotlib gallery](https://matplotlib.org/gallery.html). But like MATLAB and `numpy`, it is limited to largely numerical data. For example, notice that we had to count to where the 'wind' column was to access it. \n",
    "\n",
    "If we want additional functionality, we are going to make use of some `pandas` functionality as well as the `seaborn` package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick plots with `pandas`\n",
    "\n",
    "We can make a few quick plots on our `pandas` data frames. Notice that these are built on top of `matplotlib`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.hist('wind',bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffire.plot('X','Y','scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn! \n",
    "\n",
    "Make a `pandas` plot. Check out this [helpfile](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#other-plots) for ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More control with `seaborn`\n",
    "\n",
    "The above plots are great first images, but we may want to generate more complex plots with layers. This is where we reach for `seaborn` which is built on top of `matplotlib` (similar to how `pandas` is built on `numpy`).\n",
    "\n",
    "In this section, I am referencing the [scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) and [stripplot](https://seaborn.pydata.org/generated/seaborn.stripplot.html) helpfiles for `seaborn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot with colors in `seaborn`\n",
    "\n",
    "We will build a series of plots, adding a new feature to each one. For each plot, note what was different in the code and that difference produced. \n",
    "\n",
    "We begin with the basic `scatterplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea1 = sns.scatterplot(x=\"wind\", y=\"temp\",data=ffire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add color by month when that the fire occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea2 = sns.scatterplot(x=\"wind\", y=\"temp\",\n",
    "                       hue=\"month\",data=ffire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the style of the markers based on the day of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea3 = sns.scatterplot(x=\"wind\", y=\"temp\",hue =\"month\", \n",
    "                       style=\"day\", data=ffire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vary the size of the data points based on the area that was burned: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea4 = sns.scatterplot(x=\"wind\", y=\"temp\", size=\"area\", data=ffire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticing that many of the points lie on top of each other, let's make a `stripplot` to view the data in another way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea5 = sns.stripplot(x=\"day\", y=\"temp\", data=ffire, jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "To finish up this lab, create two posts on the **#lab02_submission** channel on slack sharing \n",
    "1. a screenshot of all your tests passing on GitHubActions\n",
    "2. a plot of the data that you imported in lab 1 that uses colors. \n",
    "\n",
    "If your have questions from this lab, post them to #lab_questions with the same preamble (i.e. starting with **Lab2**). If you have the same question, please use one of the emoji's to upvote the question. If you would like to answer someone's question, please use the thread function. This will tie your answer to their question. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources consulted to build this lab:\n",
    "\n",
    "0. _Python for Data Analysis_\n",
    "1. [Part 5](https://bmcfee.github.io/ismir2018-oss-tutorial/tutorial/2018/08/12/part-5.html) of McFee and Kell's Open MIR Tutorial\n",
    "2. Wikipedia about [hidden files](https://en.wikipedia.org/wiki/Hidden_file_and_hidden_directory)\n",
    "3. [Ignoring Files and Directories in Git with .gitignore](https://www.jamescoyle.net/how-to/1094-ignoring-files-in-git-with-gitignore)\n",
    "4. Stackoverflow question about ipynb checkpoints: [How to git ignore ipython notebook checkpoints anywhere in repository](https://stackoverflow.com/questions/35916658/how-to-git-ignore-ipython-notebook-checkpoints-anywhere-in-repository)\n",
    "5. [Selecting Subsets of Data in Pandas: Part 1](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c)\n",
    "6. [Using matplotlib in jupyter notebooks — comparing methods and some tips [Python]](https://medium.com/@1522933668924/using-matplotlib-in-jupyter-notebooks-comparing-methods-and-some-tips-python-c38e85b40ba1)\n",
    "7. [04.00-Introduction-To-Matplotlib.ipynb](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb)\n",
    "8. [plot in pandas](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html)\n",
    "9. [seaborn scatterplot helpfile](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)\n",
    "10. [seaborn stripplot helpfile](https://seaborn.pydata.org/generated/seaborn.stripplot.html) \n",
    "11. [plotting in pandas helpfile](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#other-plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
